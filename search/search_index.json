{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"hsclient A python client for interacting with HydroShare in an object oriented way. Jupyter Notebooks HydroShare has a resource with example notebooks. Click here then click the blue Open with... dropdown and select Cuahsi Jupyterhub to launch the notebooks into a Jupyter Environment to start using this project. Install the HydroShare Python Client The HydroShare Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. pip install hsclient","title":"hsclient"},{"location":"#hsclient","text":"A python client for interacting with HydroShare in an object oriented way.","title":"hsclient"},{"location":"#jupyter-notebooks","text":"HydroShare has a resource with example notebooks. Click here then click the blue Open with... dropdown and select Cuahsi Jupyterhub to launch the notebooks into a Jupyter Environment to start using this project.","title":"Jupyter Notebooks"},{"location":"#install-the-hydroshare-python-client","text":"The HydroShare Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. pip install hsclient","title":"Install the HydroShare Python Client"},{"location":"api/aggregation/","text":"Represents an Aggregation in HydroShare main_file_path: str property readonly The path to the main file in the aggregation metadata: BaseMetadata property readonly A metadata object for reading and updating metadata values metadata_file property readonly The path to the metadata file metadata_path: str property readonly The path to the metadata file aggregation(self, **kwargs) Returns a single Aggregation in the resource that matches the filtering parameters. Uses the same filtering rules described in the aggregations method. :params **kwargs: Search by properties on the metadata object :return: An Aggregation object matching the filter parameters or None if no matching Aggregation was found. Source code in hsclient/hydroshare.py def aggregation(self, **kwargs) -> BaseMetadata: \"\"\" Returns a single Aggregation in the resource that matches the filtering parameters. Uses the same filtering rules described in the aggregations method. :params **kwargs: Search by properties on the metadata object :return: An Aggregation object matching the filter parameters or None if no matching Aggregation was found. \"\"\" aggregations = self.aggregations(**kwargs) if aggregations: return aggregations[0] return None aggregations(self, **kwargs) List the aggregations in the resource. Filter by properties on the metadata object using kwargs. If you need to filter on nested properties, use __ (double underscore) to separate the properties. For example, to filter by the BandInformation name, call this method like aggregations(band_information__name=\"the name to search\"). :params **kwargs: Search by properties on the metadata object :return: a List of Aggregation objects matching the filter parameters Source code in hsclient/hydroshare.py def aggregations ( self , ** kwargs ) -> List [ BaseMetadata ] : \"\"\" List the aggregations in the resource. Filter by properties on the metadata object using kwargs. If you need to filter on nested properties, use __ (double underscore) to separate the properties. For example, to filter by the BandInformation name, call this method like aggregations(band_information__name=\" the name to search \"). :params **kwargs: Search by properties on the metadata object :return: a List of Aggregation objects matching the filter parameters \"\"\" aggregations = self . _aggregations for key , value in kwargs . items () : if key . startswith ( 'file__' ) : file_args = { key [ len('file__') : ] : value } aggregations = [ agg for agg in aggregations if agg.files(**file_args) ] elif key . startswith ( 'files__' ) : file_args = { key [ len('files__') : ] : value } aggregations = [ agg for agg in aggregations if agg.files(**file_args) ] else : aggregations = filter ( lambda agg : attribute_filter ( agg . metadata , key , value ), aggregations ) return list ( aggregations ) as_series(self, series_id, agg_path=None) Creates a pandas Series object out of an aggregation of type TimeSeries. :param series_id: The series_id of the timeseries result to be converted to a Series object. :param agg_path: Not required. Include this parameter to avoid downloading the aggregation if you already have it downloaded locally. :return: A pandas.Series object Source code in hsclient/hydroshare.py def as_series ( self , series_id : str , agg_path : str = None ) -> Dict [ int , pandas . Series ]: \"\"\" Creates a pandas Series object out of an aggregation of type TimeSeries. :param series_id: The series_id of the timeseries result to be converted to a Series object. :param agg_path: Not required. Include this parameter to avoid downloading the aggregation if you already have it downloaded locally. :return: A pandas.Series object \"\"\" def to_series ( timeseries_file : str ): con = sqlite3 . connect ( timeseries_file ) return pandas . read_sql ( f 'SELECT * FROM TimeSeriesResultValues WHERE ResultID IN ' f '(SELECT ResultID FROM Results WHERE ResultUUID = \"{series_id}\");' , con , ) . squeeze () if agg_path is None : with tempfile . TemporaryDirectory () as td : self . _download ( unzip_to = td ) # zip extracted to folder with main file name file_name = self . file ( extension = \".sqlite\" ) . name return to_series ( urljoin ( td , file_name , file_name )) return to_series ( urljoin ( agg_path , self . file ( extension = \".sqlite\" ) . name )) file(self, search_aggregations=False, **kwargs) Returns a single file in the resource that matches the filtering parameters :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: A File object matching the filter parameters or None if no matching File was found Source code in hsclient/hydroshare.py def file(self, search_aggregations=False, **kwargs) -> File: \"\"\" Returns a single file in the resource that matches the filtering parameters :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: A File object matching the filter parameters or None if no matching File was found \"\"\" files = self.files(search_aggregations=search_aggregations, **kwargs) if files: return files[0] return None files(self, search_aggregations=False, **kwargs) List files and filter by properties on the file object using kwargs (i.e. extension='.txt') :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: a List of File objects matching the filter parameters Source code in hsclient/hydroshare.py def files ( self , search_aggregations : bool = False , ** kwargs ) -> List [ File ] : \"\"\" List files and filter by properties on the file object using kwargs (i.e. extension='.txt') :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: a List of File objects matching the filter parameters \"\"\" files = self . _files for key , value in kwargs . items () : files = list ( filter ( lambda file : attribute_filter ( file , key , value ), files )) if search_aggregations : for aggregation in self . aggregations () : files = files + list ( aggregation . files ( search_aggregations = search_aggregations , ** kwargs )) return files refresh(self) Forces the retrieval of the resource map and metadata files. Currently this is implemented to be lazy and will only retrieve those files again after another call to access them is made. This will be later updated to be eager and retrieve the files asynchronously. Source code in hsclient/hydroshare.py def refresh(self) -> None: \"\"\" Forces the retrieval of the resource map and metadata files. Currently this is implemented to be lazy and will only retrieve those files again after another call to access them is made. This will be later updated to be eager and retrieve the files asynchronously. \"\"\" # TODO, refresh should destroy the aggregation objects and async fetch everything. self._retrieved_map = None self._retrieved_metadata = None self._parsed_files = None self._parsed_aggregations = None self._parsed_checksums = None save(self) Saves the metadata back to HydroShare :return: None Source code in hsclient/hydroshare.py @ refresh def save ( self ) -> None : \"\"\" Saves the metadata back to HydroShare :return: None \"\"\" metadata_file = self . metadata_file metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) url = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( url , files = { 'file' : ( metadata_file , metadata_string )})","title":"Aggregation"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation","text":"Represents an Aggregation in HydroShare","title":"hsclient.hydroshare.Aggregation"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.main_file_path","text":"The path to the main file in the aggregation","title":"main_file_path"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.metadata","text":"A metadata object for reading and updating metadata values","title":"metadata"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.metadata_file","text":"The path to the metadata file","title":"metadata_file"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.metadata_path","text":"The path to the metadata file","title":"metadata_path"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.aggregation","text":"Returns a single Aggregation in the resource that matches the filtering parameters. Uses the same filtering rules described in the aggregations method. :params **kwargs: Search by properties on the metadata object :return: An Aggregation object matching the filter parameters or None if no matching Aggregation was found. Source code in hsclient/hydroshare.py def aggregation(self, **kwargs) -> BaseMetadata: \"\"\" Returns a single Aggregation in the resource that matches the filtering parameters. Uses the same filtering rules described in the aggregations method. :params **kwargs: Search by properties on the metadata object :return: An Aggregation object matching the filter parameters or None if no matching Aggregation was found. \"\"\" aggregations = self.aggregations(**kwargs) if aggregations: return aggregations[0] return None","title":"aggregation()"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.aggregations","text":"List the aggregations in the resource. Filter by properties on the metadata object using kwargs. If you need to filter on nested properties, use __ (double underscore) to separate the properties. For example, to filter by the BandInformation name, call this method like aggregations(band_information__name=\"the name to search\"). :params **kwargs: Search by properties on the metadata object :return: a List of Aggregation objects matching the filter parameters Source code in hsclient/hydroshare.py def aggregations ( self , ** kwargs ) -> List [ BaseMetadata ] : \"\"\" List the aggregations in the resource. Filter by properties on the metadata object using kwargs. If you need to filter on nested properties, use __ (double underscore) to separate the properties. For example, to filter by the BandInformation name, call this method like aggregations(band_information__name=\" the name to search \"). :params **kwargs: Search by properties on the metadata object :return: a List of Aggregation objects matching the filter parameters \"\"\" aggregations = self . _aggregations for key , value in kwargs . items () : if key . startswith ( 'file__' ) : file_args = { key [ len('file__') : ] : value } aggregations = [ agg for agg in aggregations if agg.files(**file_args) ] elif key . startswith ( 'files__' ) : file_args = { key [ len('files__') : ] : value } aggregations = [ agg for agg in aggregations if agg.files(**file_args) ] else : aggregations = filter ( lambda agg : attribute_filter ( agg . metadata , key , value ), aggregations ) return list ( aggregations )","title":"aggregations()"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.as_series","text":"Creates a pandas Series object out of an aggregation of type TimeSeries. :param series_id: The series_id of the timeseries result to be converted to a Series object. :param agg_path: Not required. Include this parameter to avoid downloading the aggregation if you already have it downloaded locally. :return: A pandas.Series object Source code in hsclient/hydroshare.py def as_series ( self , series_id : str , agg_path : str = None ) -> Dict [ int , pandas . Series ]: \"\"\" Creates a pandas Series object out of an aggregation of type TimeSeries. :param series_id: The series_id of the timeseries result to be converted to a Series object. :param agg_path: Not required. Include this parameter to avoid downloading the aggregation if you already have it downloaded locally. :return: A pandas.Series object \"\"\" def to_series ( timeseries_file : str ): con = sqlite3 . connect ( timeseries_file ) return pandas . read_sql ( f 'SELECT * FROM TimeSeriesResultValues WHERE ResultID IN ' f '(SELECT ResultID FROM Results WHERE ResultUUID = \"{series_id}\");' , con , ) . squeeze () if agg_path is None : with tempfile . TemporaryDirectory () as td : self . _download ( unzip_to = td ) # zip extracted to folder with main file name file_name = self . file ( extension = \".sqlite\" ) . name return to_series ( urljoin ( td , file_name , file_name )) return to_series ( urljoin ( agg_path , self . file ( extension = \".sqlite\" ) . name ))","title":"as_series()"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.file","text":"Returns a single file in the resource that matches the filtering parameters :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: A File object matching the filter parameters or None if no matching File was found Source code in hsclient/hydroshare.py def file(self, search_aggregations=False, **kwargs) -> File: \"\"\" Returns a single file in the resource that matches the filtering parameters :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: A File object matching the filter parameters or None if no matching File was found \"\"\" files = self.files(search_aggregations=search_aggregations, **kwargs) if files: return files[0] return None","title":"file()"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.files","text":"List files and filter by properties on the file object using kwargs (i.e. extension='.txt') :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: a List of File objects matching the filter parameters Source code in hsclient/hydroshare.py def files ( self , search_aggregations : bool = False , ** kwargs ) -> List [ File ] : \"\"\" List files and filter by properties on the file object using kwargs (i.e. extension='.txt') :param search_aggregations: Defaults False, set to true to search aggregations :params **kwargs: Search by properties on the File object (path, name, extension, folder, checksum url) :return: a List of File objects matching the filter parameters \"\"\" files = self . _files for key , value in kwargs . items () : files = list ( filter ( lambda file : attribute_filter ( file , key , value ), files )) if search_aggregations : for aggregation in self . aggregations () : files = files + list ( aggregation . files ( search_aggregations = search_aggregations , ** kwargs )) return files","title":"files()"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.refresh","text":"Forces the retrieval of the resource map and metadata files. Currently this is implemented to be lazy and will only retrieve those files again after another call to access them is made. This will be later updated to be eager and retrieve the files asynchronously. Source code in hsclient/hydroshare.py def refresh(self) -> None: \"\"\" Forces the retrieval of the resource map and metadata files. Currently this is implemented to be lazy and will only retrieve those files again after another call to access them is made. This will be later updated to be eager and retrieve the files asynchronously. \"\"\" # TODO, refresh should destroy the aggregation objects and async fetch everything. self._retrieved_map = None self._retrieved_metadata = None self._parsed_files = None self._parsed_aggregations = None self._parsed_checksums = None","title":"refresh()"},{"location":"api/aggregation/#hsclient.hydroshare.Aggregation.save","text":"Saves the metadata back to HydroShare :return: None Source code in hsclient/hydroshare.py @ refresh def save ( self ) -> None : \"\"\" Saves the metadata back to HydroShare :return: None \"\"\" metadata_file = self . metadata_file metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) url = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( url , files = { 'file' : ( metadata_file , metadata_string )})","title":"save()"},{"location":"api/file/","text":"A File path string representing the path to a file within a resource. :param value: the string path value :param file_url: the fully qualified url to the file on hydroshare.org :param checksum: the md5 checksum of the file checksum property readonly The md5 checksum of the file extension: str property readonly The extension of the file folder: str property readonly The folder the file is in name: str property readonly The filename path: str property readonly The path of the file url property readonly The url to the file on HydroShare __new__(cls, value, file_url, checksum) special staticmethod Create and return a new object. See help(type) for accurate signature. Source code in hsclient/hydroshare.py def __new__(cls, value, file_url, checksum): return super(File, cls).__new__(cls, value)","title":"File"},{"location":"api/file/#hsclient.hydroshare.File","text":"A File path string representing the path to a file within a resource. :param value: the string path value :param file_url: the fully qualified url to the file on hydroshare.org :param checksum: the md5 checksum of the file","title":"hsclient.hydroshare.File"},{"location":"api/file/#hsclient.hydroshare.File.checksum","text":"The md5 checksum of the file","title":"checksum"},{"location":"api/file/#hsclient.hydroshare.File.extension","text":"The extension of the file","title":"extension"},{"location":"api/file/#hsclient.hydroshare.File.folder","text":"The folder the file is in","title":"folder"},{"location":"api/file/#hsclient.hydroshare.File.name","text":"The filename","title":"name"},{"location":"api/file/#hsclient.hydroshare.File.path","text":"The path of the file","title":"path"},{"location":"api/file/#hsclient.hydroshare.File.url","text":"The url to the file on HydroShare","title":"url"},{"location":"api/file/#hsclient.hydroshare.File.__new__","text":"Create and return a new object. See help(type) for accurate signature. Source code in hsclient/hydroshare.py def __new__(cls, value, file_url, checksum): return super(File, cls).__new__(cls, value)","title":"__new__()"},{"location":"api/hydroshare/","text":"A HydroShare object for querying HydroShare's REST API. Provide a username and password at initialization or call the sign_in() method to prompt for the username and password. If using OAuth2 is desired, provide the client_id and token to use. If on CUAHSI JupyterHub or another JupyterHub environment that authenticates with Hydroshare, call the hs_juptyerhub() method to read the credentials from Jupyterhub. :param username: A HydroShare username :param password: A HydroShare password associated with the username :param host: The host to use, defaults to www.hydroshare.org :param protocol: The protocol to use, defaults to https :param port: The port to use, defaults to 443 :param client_id: The client id associated with the OAuth2 token :param token: The OAuth2 token to use create(self, use_cache=True) Creates a new resource on HydroShare :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare Source code in hsclient/hydroshare.py def create(self, use_cache: bool = True) -> Resource: \"\"\" Creates a new resource on HydroShare :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" response = self._hs_session.post('/hsapi/resource/', status_code=201) resource_id = response.json()['resource_id'] return self.resource(resource_id, use_cache=use_cache) hs_juptyerhub(hs_auth_path='/home/jovyan/data/.hs_auth') classmethod Create a new HydroShare object using OAuth2 credentials stored in a canonical CUAHSI Jupyterhub OAuth2 pickle file (stored at :param hs_auth_path:). Provide a non-default (default: /home/jovyan/data/.hs_auth ) path to the hs_auth file with :param hs_auth_path:. Source code in hsclient/hydroshare.py @ classmethod def hs_juptyerhub ( cls , hs_auth_path = \"/home/jovyan/data/.hs_auth\" ): \"\"\" Create a new HydroShare object using OAuth2 credentials stored in a canonical CUAHSI Jupyterhub OAuth2 pickle file (stored at :param hs_auth_path:). Provide a non-default (default: `/home/jovyan/data/.hs_auth`) path to the hs_auth file with :param hs_auth_path:. \"\"\" if not os . path . isfile ( hs_auth_path ): raise ValueError ( f \"hs_auth_path {hs_auth_path} does not exist.\" ) with open ( hs_auth_path , 'rb' ) as f : token , client_id = pickle . load ( f ) instance = cls ( client_id = client_id , token = token ) instance . my_user_info () # validate credentials return instance my_user_info(self) Retrieves the user info of the user's credentials provided :return: JSON object representing the user info Source code in hsclient/hydroshare.py def my_user_info(self): \"\"\" Retrieves the user info of the user's credentials provided :return: JSON object representing the user info \"\"\" response = self._hs_session.get('/hsapi/userInfo/', status_code=200) return response.json() resource(self, resource_id, validate=True, use_cache=True) Creates a resource object from HydroShare with the provided resource_id :param resource_id: The resource id of the resource to retrieve :param validate: Defaults to True, set to False to not validate the resource exists :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare Source code in hsclient/hydroshare.py def resource ( self , resource_id : str , validate : bool = True , use_cache : bool = True ) -> Resource : \"\"\" Creates a resource object from HydroShare with the provided resource_id :param resource_id: The resource id of the resource to retrieve :param validate: Defaults to True, set to False to not validate the resource exists :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" if resource_id in self . _resource_object_cache and use_cache : return self . _resource_object_cache [ resource_id ] res = Resource ( \"/resource/{}/data/resourcemap.xml\" . format ( resource_id ), self . _hs_session ) if validate : res . metadata if use_cache : self . _resource_object_cache [ resource_id ] = res return res search(self, creator=None, contributor=None, owner=None, group_name=None, from_date=None, to_date=None, edit_permission=False, resource_types=[], subject=[], full_text_search=None, published=False, spatial_coverage=None) Query the GET /hsapi/resource/ REST end point of the HydroShare server. :param creator: Filter results by the HydroShare username or email :param author: Filter results by the HydroShare username or email :param owner: Filter results by the HydroShare username or email :param group_name: Filter results by the HydroShare group name associated with resources :param from_date: Filter results to those created after from_date. Must be datetime.date. :param to_date: Filter results to those created before to_date. Must be datetime.date. Because dates have no time information, you must specify date+1 day to get results for date (e.g. use 2015-05-06 to get resources created up to and including 2015-05-05) :param types: Filter results to particular HydroShare resource types (Deprecated, all types are Composite) :param subject: Filter by comma separated list of subjects :param full_text_search: Filter by full text search :param edit_permission: Filter by boolean edit permission :param published: Filter by boolean published status :param spatial_coverage: Filtering by spatial coverage raises a 500, do not use :return: A generator to iterate over a ResourcePreview object Source code in hsclient/hydroshare.py def search ( self , creator : str = None , contributor : str = None , owner : str = None , group_name : str = None , from_date : datetime = None , to_date : datetime = None , edit_permission : bool = False , resource_types : List [ str ] = [] , subject : List [ str ] = [] , full_text_search : str = None , published : bool = False , spatial_coverage : Union [ BoxCoverage, PointCoverage ] = None , ) : \"\"\" Query the GET /hsapi/resource/ REST end point of the HydroShare server. :param creator: Filter results by the HydroShare username or email :param author: Filter results by the HydroShare username or email :param owner: Filter results by the HydroShare username or email :param group_name: Filter results by the HydroShare group name associated with resources :param from_date: Filter results to those created after from_date. Must be datetime.date. :param to_date: Filter results to those created before to_date. Must be datetime.date. Because dates have no time information, you must specify date+1 day to get results for date (e.g. use 2015-05-06 to get resources created up to and including 2015-05-05) :param types: Filter results to particular HydroShare resource types (Deprecated, all types are Composite) :param subject: Filter by comma separated list of subjects :param full_text_search: Filter by full text search :param edit_permission: Filter by boolean edit permission :param published: Filter by boolean published status :param spatial_coverage: Filtering by spatial coverage raises a 500, do not use :return: A generator to iterate over a ResourcePreview object \"\"\" params = { \"edit_permission\" : edit_permission , \"published\" : published } if creator : params [ \"creator\" ] = creator if contributor : params [ \"author\" ] = contributor if owner : params [ \"owner\" ] = owner if group_name : params [ \"group\" ] = group_name if resource_types : params [ \"type[ ] \"] = resource_types if subject: params[\" subject \"] = \" , \".join(subject) if full_text_search: params[\" full_text_search \"] = full_text_search if from_date: params[\" from_date \"] = from_date.strftime('%Y-%m-%d') if to_date: params[\" to_date \"] = to_date.strftime('%Y-%m-%d') if spatial_coverage: params[\" coverage_type \"] = spatial_coverage.type if spatial_coverage.type == \" point \": params[\" north \"] = spatial_coverage.north params[\" east \"] = spatial_coverage.east else: params[\" north \"] = spatial_coverage.northlimit params[\" east \"] = spatial_coverage.eastlimit params[\" south \"] = spatial_coverage.southlimit params[\" west \"] = spatial_coverage.westlimit response = self._hs_session.get(\" / hsapi / resource / \" , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item ) while res [ 'next' ] : next_url = res [ 'next' ] next_url = urlparse ( next_url ) path = next_url . path params = next_url . query response = self . _hs_session . get ( path , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item ) sign_in(self) Prompts for username/password. Useful for avoiding saving your HydroShare credentials to a notebook Source code in hsclient/hydroshare.py def sign_in(self) -> None: \"\"\"Prompts for username/password. Useful for avoiding saving your HydroShare credentials to a notebook\"\"\" username = input(\"Username: \").strip() password = getpass.getpass(\"Password for {}: \".format(username)) self._hs_session.set_auth((username, password)) self.my_user_info() # validate credentials user(self, user_id) Retrieves the user details of a Hydroshare user :param user_id: The user id of the user details to retrieve :return: User object representing the user details Source code in hsclient/hydroshare.py def user(self, user_id: int) -> User: \"\"\" Retrieves the user details of a Hydroshare user :param user_id: The user id of the user details to retrieve :return: User object representing the user details \"\"\" response = self._hs_session.get(f'/hsapi/userDetails/{user_id}/', status_code=200) return User(**response.json())","title":"HydroShare"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare","text":"A HydroShare object for querying HydroShare's REST API. Provide a username and password at initialization or call the sign_in() method to prompt for the username and password. If using OAuth2 is desired, provide the client_id and token to use. If on CUAHSI JupyterHub or another JupyterHub environment that authenticates with Hydroshare, call the hs_juptyerhub() method to read the credentials from Jupyterhub. :param username: A HydroShare username :param password: A HydroShare password associated with the username :param host: The host to use, defaults to www.hydroshare.org :param protocol: The protocol to use, defaults to https :param port: The port to use, defaults to 443 :param client_id: The client id associated with the OAuth2 token :param token: The OAuth2 token to use","title":"hsclient.hydroshare.HydroShare"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.create","text":"Creates a new resource on HydroShare :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare Source code in hsclient/hydroshare.py def create(self, use_cache: bool = True) -> Resource: \"\"\" Creates a new resource on HydroShare :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" response = self._hs_session.post('/hsapi/resource/', status_code=201) resource_id = response.json()['resource_id'] return self.resource(resource_id, use_cache=use_cache)","title":"create()"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.hs_juptyerhub","text":"Create a new HydroShare object using OAuth2 credentials stored in a canonical CUAHSI Jupyterhub OAuth2 pickle file (stored at :param hs_auth_path:). Provide a non-default (default: /home/jovyan/data/.hs_auth ) path to the hs_auth file with :param hs_auth_path:. Source code in hsclient/hydroshare.py @ classmethod def hs_juptyerhub ( cls , hs_auth_path = \"/home/jovyan/data/.hs_auth\" ): \"\"\" Create a new HydroShare object using OAuth2 credentials stored in a canonical CUAHSI Jupyterhub OAuth2 pickle file (stored at :param hs_auth_path:). Provide a non-default (default: `/home/jovyan/data/.hs_auth`) path to the hs_auth file with :param hs_auth_path:. \"\"\" if not os . path . isfile ( hs_auth_path ): raise ValueError ( f \"hs_auth_path {hs_auth_path} does not exist.\" ) with open ( hs_auth_path , 'rb' ) as f : token , client_id = pickle . load ( f ) instance = cls ( client_id = client_id , token = token ) instance . my_user_info () # validate credentials return instance","title":"hs_juptyerhub()"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.my_user_info","text":"Retrieves the user info of the user's credentials provided :return: JSON object representing the user info Source code in hsclient/hydroshare.py def my_user_info(self): \"\"\" Retrieves the user info of the user's credentials provided :return: JSON object representing the user info \"\"\" response = self._hs_session.get('/hsapi/userInfo/', status_code=200) return response.json()","title":"my_user_info()"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.resource","text":"Creates a resource object from HydroShare with the provided resource_id :param resource_id: The resource id of the resource to retrieve :param validate: Defaults to True, set to False to not validate the resource exists :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare Source code in hsclient/hydroshare.py def resource ( self , resource_id : str , validate : bool = True , use_cache : bool = True ) -> Resource : \"\"\" Creates a resource object from HydroShare with the provided resource_id :param resource_id: The resource id of the resource to retrieve :param validate: Defaults to True, set to False to not validate the resource exists :param use_cache: Defaults to True, set to False to skip the cache, and always retrieve the resource from HydroShare. This parameter also does not cache the retrieved Resource object. :return: A Resource object representing a resource on HydroShare \"\"\" if resource_id in self . _resource_object_cache and use_cache : return self . _resource_object_cache [ resource_id ] res = Resource ( \"/resource/{}/data/resourcemap.xml\" . format ( resource_id ), self . _hs_session ) if validate : res . metadata if use_cache : self . _resource_object_cache [ resource_id ] = res return res","title":"resource()"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.search","text":"Query the GET /hsapi/resource/ REST end point of the HydroShare server. :param creator: Filter results by the HydroShare username or email :param author: Filter results by the HydroShare username or email :param owner: Filter results by the HydroShare username or email :param group_name: Filter results by the HydroShare group name associated with resources :param from_date: Filter results to those created after from_date. Must be datetime.date. :param to_date: Filter results to those created before to_date. Must be datetime.date. Because dates have no time information, you must specify date+1 day to get results for date (e.g. use 2015-05-06 to get resources created up to and including 2015-05-05) :param types: Filter results to particular HydroShare resource types (Deprecated, all types are Composite) :param subject: Filter by comma separated list of subjects :param full_text_search: Filter by full text search :param edit_permission: Filter by boolean edit permission :param published: Filter by boolean published status :param spatial_coverage: Filtering by spatial coverage raises a 500, do not use :return: A generator to iterate over a ResourcePreview object Source code in hsclient/hydroshare.py def search ( self , creator : str = None , contributor : str = None , owner : str = None , group_name : str = None , from_date : datetime = None , to_date : datetime = None , edit_permission : bool = False , resource_types : List [ str ] = [] , subject : List [ str ] = [] , full_text_search : str = None , published : bool = False , spatial_coverage : Union [ BoxCoverage, PointCoverage ] = None , ) : \"\"\" Query the GET /hsapi/resource/ REST end point of the HydroShare server. :param creator: Filter results by the HydroShare username or email :param author: Filter results by the HydroShare username or email :param owner: Filter results by the HydroShare username or email :param group_name: Filter results by the HydroShare group name associated with resources :param from_date: Filter results to those created after from_date. Must be datetime.date. :param to_date: Filter results to those created before to_date. Must be datetime.date. Because dates have no time information, you must specify date+1 day to get results for date (e.g. use 2015-05-06 to get resources created up to and including 2015-05-05) :param types: Filter results to particular HydroShare resource types (Deprecated, all types are Composite) :param subject: Filter by comma separated list of subjects :param full_text_search: Filter by full text search :param edit_permission: Filter by boolean edit permission :param published: Filter by boolean published status :param spatial_coverage: Filtering by spatial coverage raises a 500, do not use :return: A generator to iterate over a ResourcePreview object \"\"\" params = { \"edit_permission\" : edit_permission , \"published\" : published } if creator : params [ \"creator\" ] = creator if contributor : params [ \"author\" ] = contributor if owner : params [ \"owner\" ] = owner if group_name : params [ \"group\" ] = group_name if resource_types : params [ \"type[ ] \"] = resource_types if subject: params[\" subject \"] = \" , \".join(subject) if full_text_search: params[\" full_text_search \"] = full_text_search if from_date: params[\" from_date \"] = from_date.strftime('%Y-%m-%d') if to_date: params[\" to_date \"] = to_date.strftime('%Y-%m-%d') if spatial_coverage: params[\" coverage_type \"] = spatial_coverage.type if spatial_coverage.type == \" point \": params[\" north \"] = spatial_coverage.north params[\" east \"] = spatial_coverage.east else: params[\" north \"] = spatial_coverage.northlimit params[\" east \"] = spatial_coverage.eastlimit params[\" south \"] = spatial_coverage.southlimit params[\" west \"] = spatial_coverage.westlimit response = self._hs_session.get(\" / hsapi / resource / \" , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item ) while res [ 'next' ] : next_url = res [ 'next' ] next_url = urlparse ( next_url ) path = next_url . path params = next_url . query response = self . _hs_session . get ( path , 200 , params = params ) res = response . json () results = res [ 'results' ] for item in results : yield ResourcePreview ( ** item )","title":"search()"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.sign_in","text":"Prompts for username/password. Useful for avoiding saving your HydroShare credentials to a notebook Source code in hsclient/hydroshare.py def sign_in(self) -> None: \"\"\"Prompts for username/password. Useful for avoiding saving your HydroShare credentials to a notebook\"\"\" username = input(\"Username: \").strip() password = getpass.getpass(\"Password for {}: \".format(username)) self._hs_session.set_auth((username, password)) self.my_user_info() # validate credentials","title":"sign_in()"},{"location":"api/hydroshare/#hsclient.hydroshare.HydroShare.user","text":"Retrieves the user details of a Hydroshare user :param user_id: The user id of the user details to retrieve :return: User object representing the user details Source code in hsclient/hydroshare.py def user(self, user_id: int) -> User: \"\"\" Retrieves the user details of a Hydroshare user :param user_id: The user id of the user details to retrieve :return: User object representing the user details \"\"\" response = self._hs_session.get(f'/hsapi/userDetails/{user_id}/', status_code=200) return User(**response.json())","title":"user()"},{"location":"api/resource/","text":"Represents a Resource in HydroShare access_permission property readonly Retrieves the access permissions of the resource :return: JSON object metadata_file property readonly The path to the metadata file resource_id: str property readonly The resource id (guid) of the HydroShare resource aggregation_delete(self, aggregation) Deletes an aggregation from HydroShare. This deletes the files and metadata in the aggregation. :param aggregation: The aggregation object to delete :return: None Source code in hsclient/hydroshare.py @refresh def aggregation_delete(self, aggregation: Aggregation) -> None: \"\"\" Deletes an aggregation from HydroShare. This deletes the files and metadata in the aggregation. :param aggregation: The aggregation object to delete :return: None \"\"\" path = urljoin( aggregation._hsapi_path, \"functions\", \"delete-file-type\", aggregation.metadata.type.value + \"LogicalFile\", aggregation.main_file_path, ) aggregation._hs_session.delete(path, status_code=200) aggregation.refresh() aggregation_download(self, aggregation, save_path='', unzip_to=None) Download an aggregation from HydroShare :param aggregation: The aggreation to download :param save_path: The local path to save the aggregation to, defaults to the current directory :param unzip_to: If set, the resulting download will be unzipped to the specified path :return: None Source code in hsclient/hydroshare.py def aggregation_download ( self , aggregation : Aggregation , save_path : str = \"\" , unzip_to : str = None ) -> str : \"\"\" Download an aggregation from HydroShare :param aggregation: The aggreation to download :param save_path: The local path to save the aggregation to, defaults to the current directory :param unzip_to: If set, the resulting download will be unzipped to the specified path :return: None \"\"\" return aggregation . _download ( save_path = save_path , unzip_to = unzip_to ) aggregation_remove(self, aggregation) Removes an aggregation from HydroShare. This does not remove the files in the aggregation. :param aggregation: The aggregation object to remove :return: None Source code in hsclient/hydroshare.py @refresh def aggregation_remove(self, aggregation: Aggregation) -> None: \"\"\" Removes an aggregation from HydroShare. This does not remove the files in the aggregation. :param aggregation: The aggregation object to remove :return: None \"\"\" path = urljoin( aggregation._hsapi_path, \"functions\", \"remove-file-type\", aggregation.metadata.type.value + \"LogicalFile\", aggregation.main_file_path, ) aggregation._hs_session.post(path, status_code=200) aggregation.refresh() copy(self) Copies this Resource into a new resource on HydroShare returns: A Resource object of the newly copied resource Source code in hsclient/hydroshare.py def copy(self): \"\"\" Copies this Resource into a new resource on HydroShare returns: A Resource object of the newly copied resource \"\"\" path = urljoin(self._hsapi_path, \"copy\") response = self._hs_session.post(path, status_code=202) resource_id = response.text return Resource(\"/resource/{}/data/resourcemap.xml\".format(resource_id), self._hs_session) delete(self) Deletes the resource on HydroShare :return: None Source code in hsclient/hydroshare.py @refresh def delete(self) -> None: \"\"\" Deletes the resource on HydroShare :return: None \"\"\" hsapi_path = self._hsapi_path self._hs_session.delete(hsapi_path, status_code=204) download(self, save_path='') Downloads a zipped bagit archive of the resource from HydroShare param save_path: A local path to save the bag to, defaults to the current working directory returns: The relative pathname of the download Source code in hsclient/hydroshare.py def download ( self , save_path : str = \"\" ) -> str : \"\"\" Downloads a zipped bagit archive of the resource from HydroShare param save_path: A local path to save the bag to, defaults to the current working directory returns: The relative pathname of the download \"\"\" return self . _hs_session . retrieve_bag ( self . _hsapi_path , save_path = save_path ) file_aggregate(self, path, agg_type, refresh=True) Aggregate a file to a HydroShare aggregation type. Aggregating files allows you to specify metadata specific to the files associated with the aggregation. To set a FileSet aggregation, include the path to the folder or a file in the folder you would like to create a FileSet aggregation from. :param path: The path to the file to aggregate :param agg_type: The AggregationType to create :param refresh: Defaults True, toggles automatic refreshing of the updated resource in HydroShare :return: The newly created Aggregation object if refresh is True Source code in hsclient/hydroshare.py def file_aggregate ( self , path: str , agg_type: AggregationType , refresh: bool = True ) : \"\"\" Aggregate a file to a HydroShare aggregation type . Aggregating files allows you to specify metadata specific to the files associated with the aggregation . To set a FileSet aggregation , include the path to the folder or a file in the folder you would like to create a FileSet aggregation from . : param path: The path to the file to aggregate : param agg_type: The AggregationType to create : param refresh: Defaults True , toggles automatic refreshing of the updated resource in HydroShare : return : The newly created Aggregation object if refresh is True \"\"\" type_value = agg_type . value data = {} if agg_type == AggregationType . SingleFileAggregation: type_value = ' SingleFile ' if agg_type == AggregationType . FileSetAggregation: relative_path = dirname ( path ) data = { \"folder_path\" : relative_path } url = urljoin ( self . _hsapi_path , \"functions\" , \"set-file-type\" , path , type_value ) self . _hs_session . post ( url , status_code = 201 , data = data ) if refresh: # Only return the newly created aggregation if a refresh is requested self . refresh () return self . aggregation ( file__path = path ) file_delete(self, path=None) Delete a file on HydroShare :param path: The path to the file :return: None Source code in hsclient/hydroshare.py @refresh def file_delete(self, path: str = None) -> None: \"\"\" Delete a file on HydroShare :param path: The path to the file :return: None \"\"\" self._delete_file(path) file_download(self, path, save_path='', zipped=False) Downloads a file from HydroShare :param path: The path to the file :param save_path: The local path to save the file to :param zipped: Defaults to False, set to True to download the file zipped :return: The path to the downloaded file Source code in hsclient/hydroshare.py def file_download ( self , path : str , save_path : str = \"\" , zipped : bool = False ): \"\"\" Downloads a file from HydroShare :param path: The path to the file :param save_path: The local path to save the file to :param zipped: Defaults to False, set to True to download the file zipped :return: The path to the downloaded file \"\"\" if zipped : return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } ) else : return self . _hs_session . retrieve_file ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path ) file_rename(self, path, new_path) Rename a file on HydroShare :param path: The path to the file :param new_path: the renamed path to the file :return: None Source code in hsclient/hydroshare.py @refresh def file_rename(self, path: str, new_path: str) -> None: \"\"\" Rename a file on HydroShare :param path: The path to the file :param new_path: the renamed path to the file :return: None \"\"\" rename_path = urljoin(self._hsapi_path, \"functions\", \"move-or-rename\") self._hs_session.post(rename_path, status_code=200, data={\"source_path\": path, \"target_path\": new_path}) file_unzip(self, path, overwrite=True, ingest_metadata=True) Unzips a file on HydroShare :param path: The path to the file to unzip :param overwrite: Defaults to True, set to False to unzip the files into a folder with the zip filename :param ingest_metadata: Defaults to True, set to False to not ingest HydroShare RDF metadata xml files :return: None Source code in hsclient/hydroshare.py @refresh def file_unzip(self, path: str, overwrite: bool = True, ingest_metadata=True) -> None: \"\"\" Unzips a file on HydroShare :param path: The path to the file to unzip :param overwrite: Defaults to True, set to False to unzip the files into a folder with the zip filename :param ingest_metadata: Defaults to True, set to False to not ingest HydroShare RDF metadata xml files :return: None \"\"\" if not path.endswith(\".zip\"): raise Exception(\"File {} is not a zip, and cannot be unzipped\".format(path)) unzip_path = urljoin(self._hsapi_path, \"functions\", \"unzip\", \"data\", \"contents\", path) self._hs_session.post( unzip_path, status_code=200, data={\"overwrite\": overwrite, \"ingest_metadata\": ingest_metadata} ) file_upload(self, *files, *, destination_path='') Uploads files to a folder in HydroShare :param *files: The local file paths to upload :param destination_path: The path on HydroShare to upload the files to, defaults to the root contents directory :return: None Source code in hsclient/hydroshare.py @ refresh def file_upload ( self , * files : str , destination_path : str = \"\" ) -> None : \"\"\" Uploads files to a folder in HydroShare :param *files: The local file paths to upload :param destination_path: The path on HydroShare to upload the files to, defaults to the root contents directory :return: None \"\"\" if len ( files ) == 1 : self . _upload ( files [ 0 ], destination_path = destination_path ) else : with tempfile . TemporaryDirectory () as tmpdir : zipped_file = os . path . join ( tmpdir , 'files.zip' ) with ZipFile ( zipped_file , 'w' ) as zipped : for file in files : zipped . write ( file , os . path . basename ( file )) self . _upload ( zipped_file , destination_path = destination_path ) unzip_path = urljoin ( self . _hsapi_path , \"functions\" , \"unzip\" , \"data\" , \"contents\" , destination_path , 'files.zip' ) self . _hs_session . post ( unzip_path , status_code = 200 , data = { \"overwrite\" : \"true\" , \"ingest_metadata\" : \"true\" } ) file_zip(self, path, zip_name=None, remove_file=True) Zip a file on HydroShare :param path: The path to the file :param zip_name: The name of the zipped file :param remove_file: Defaults to True, set to False to not delete the file that was zipped :return: None Source code in hsclient/hydroshare.py @refresh def file_zip(self, path: str, zip_name: str = None, remove_file: bool = True) -> None: \"\"\" Zip a file on HydroShare :param path: The path to the file :param zip_name: The name of the zipped file :param remove_file: Defaults to True, set to False to not delete the file that was zipped :return: None \"\"\" zip_name = basename(path) + \".zip\" if not zip_name else zip_name data = {\"input_coll_path\": path, \"output_zip_file_name\": zip_name, \"remove_original_after_zip\": remove_file} zip_path = urljoin(self._hsapi_path, \"functions\", \"zip\") self._hs_session.post(zip_path, status_code=200, data=data) folder_create(self, folder) Creates a folder on HydroShare :param folder: the folder path to create :return: None Source code in hsclient/hydroshare.py @refresh def folder_create(self, folder: str) -> None: \"\"\" Creates a folder on HydroShare :param folder: the folder path to create :return: None \"\"\" path = urljoin(self._hsapi_path, \"folders\", folder) self._hs_session.put(path, status_code=201) folder_delete(self, path=None) Deletes a folder on HydroShare :param path: the path to the folder :return: None Source code in hsclient/hydroshare.py @refresh def folder_delete(self, path: str = None) -> None: \"\"\" Deletes a folder on HydroShare :param path: the path to the folder :return: None \"\"\" self._delete_file_folder(path) folder_download(self, path, save_path='') Downloads a folder from HydroShare :param path: The path to folder :param save_path: The local path to save the download to, defaults to the current directory :return: The path to the download zipped folder Source code in hsclient/hydroshare.py def folder_download ( self , path : str , save_path : str = \"\" ): \"\"\" Downloads a folder from HydroShare :param path: The path to folder :param save_path: The local path to save the download to, defaults to the current directory :return: The path to the download zipped folder \"\"\" return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } ) folder_rename(self, path, new_path) Renames a folder on HydroShare :param path: the path to the folder to rename :param new_path: the new path folder name :return: None Source code in hsclient/hydroshare.py @refresh def folder_rename(self, path: str, new_path: str) -> None: \"\"\" Renames a folder on HydroShare :param path: the path to the folder to rename :param new_path: the new path folder name :return: None \"\"\" self.file_rename(path=path, new_path=new_path) new_version(self) Creates a new version of the resource on HydroShare :return: A Resource object of the newly created resource version Source code in hsclient/hydroshare.py def new_version(self): \"\"\" Creates a new version of the resource on HydroShare :return: A Resource object of the newly created resource version \"\"\" path = urljoin(self._hsapi_path, \"version\") response = self._hs_session.post(path, status_code=202) resource_id = response.text return Resource(\"/resource/{}/data/resourcemap.xml\".format(resource_id), self._hs_session) reference_create(self, file_name, url, path='') Creates a HydroShare reference object to reference content outside of the resource :param file_name: the file name of the resulting .url file :param url: the url of the referenced content :param path: the path to create the reference in :return: None Source code in hsclient/hydroshare.py @refresh def reference_create(self, file_name: str, url: str, path: str = '') -> None: \"\"\" Creates a HydroShare reference object to reference content outside of the resource :param file_name: the file name of the resulting .url file :param url: the url of the referenced content :param path: the path to create the reference in :return: None \"\"\" request_path = urljoin(self._hsapi_path.replace(self.resource_id, \"\"), \"data-store-add-reference\") self._hs_session.post( request_path, data={\"res_id\": self.resource_id, \"curr_path\": path, \"ref_name\": file_name, \"ref_url\": url}, status_code=200, ) reference_update(self, file_name, url, path='') Updates a HydroShare reference object :param file_name: the file name for the .url file :param url: the url of the referenced content :param path: the path to the directory where the reference is located :return: None Source code in hsclient/hydroshare.py @refresh def reference_update(self, file_name: str, url: str, path: str = '') -> None: \"\"\" Updates a HydroShare reference object :param file_name: the file name for the .url file :param url: the url of the referenced content :param path: the path to the directory where the reference is located :return: None \"\"\" request_path = urljoin(self._hsapi_path.replace(self.resource_id, \"\"), \"data_store_edit_reference_url\") self._hs_session.post( request_path, data={\"res_id\": self.resource_id, \"curr_path\": path, \"url_filename\": file_name, \"new_ref_url\": url}, status_code=200, ) save(self) Saves the metadata to HydroShare :return: None Source code in hsclient/hydroshare.py @ refresh def save ( self ) -> None : \"\"\" Saves the metadata to HydroShare :return: None \"\"\" metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) path = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( path , files = { 'file' : ( 'resourcemetadata.xml' , metadata_string )}) set_sharing_status(self, public) Set the sharing status of the resource to public or private :param public: bool, set to True for public, False for private Source code in hsclient/hydroshare.py def set_sharing_status(self, public: bool): \"\"\" Set the sharing status of the resource to public or private :param public: bool, set to True for public, False for private \"\"\" path = urljoin(\"hsapi\", \"resource\", \"accessRules\", self.resource_id) data = {'public': public} self._hs_session.put(path, status_code=200, data=data) system_metadata(self) The system metadata associated with the HydroShare resource returns: JSON object Source code in hsclient/hydroshare.py def system_metadata(self): \"\"\" The system metadata associated with the HydroShare resource returns: JSON object \"\"\" hsapi_path = urljoin(self._hsapi_path, 'sysmeta') return self._hs_session.get(hsapi_path, status_code=200).json()","title":"Resource"},{"location":"api/resource/#hsclient.hydroshare.Resource","text":"Represents a Resource in HydroShare","title":"hsclient.hydroshare.Resource"},{"location":"api/resource/#hsclient.hydroshare.Resource.access_permission","text":"Retrieves the access permissions of the resource :return: JSON object","title":"access_permission"},{"location":"api/resource/#hsclient.hydroshare.Resource.metadata_file","text":"The path to the metadata file","title":"metadata_file"},{"location":"api/resource/#hsclient.hydroshare.Resource.resource_id","text":"The resource id (guid) of the HydroShare resource","title":"resource_id"},{"location":"api/resource/#hsclient.hydroshare.Resource.aggregation_delete","text":"Deletes an aggregation from HydroShare. This deletes the files and metadata in the aggregation. :param aggregation: The aggregation object to delete :return: None Source code in hsclient/hydroshare.py @refresh def aggregation_delete(self, aggregation: Aggregation) -> None: \"\"\" Deletes an aggregation from HydroShare. This deletes the files and metadata in the aggregation. :param aggregation: The aggregation object to delete :return: None \"\"\" path = urljoin( aggregation._hsapi_path, \"functions\", \"delete-file-type\", aggregation.metadata.type.value + \"LogicalFile\", aggregation.main_file_path, ) aggregation._hs_session.delete(path, status_code=200) aggregation.refresh()","title":"aggregation_delete()"},{"location":"api/resource/#hsclient.hydroshare.Resource.aggregation_download","text":"Download an aggregation from HydroShare :param aggregation: The aggreation to download :param save_path: The local path to save the aggregation to, defaults to the current directory :param unzip_to: If set, the resulting download will be unzipped to the specified path :return: None Source code in hsclient/hydroshare.py def aggregation_download ( self , aggregation : Aggregation , save_path : str = \"\" , unzip_to : str = None ) -> str : \"\"\" Download an aggregation from HydroShare :param aggregation: The aggreation to download :param save_path: The local path to save the aggregation to, defaults to the current directory :param unzip_to: If set, the resulting download will be unzipped to the specified path :return: None \"\"\" return aggregation . _download ( save_path = save_path , unzip_to = unzip_to )","title":"aggregation_download()"},{"location":"api/resource/#hsclient.hydroshare.Resource.aggregation_remove","text":"Removes an aggregation from HydroShare. This does not remove the files in the aggregation. :param aggregation: The aggregation object to remove :return: None Source code in hsclient/hydroshare.py @refresh def aggregation_remove(self, aggregation: Aggregation) -> None: \"\"\" Removes an aggregation from HydroShare. This does not remove the files in the aggregation. :param aggregation: The aggregation object to remove :return: None \"\"\" path = urljoin( aggregation._hsapi_path, \"functions\", \"remove-file-type\", aggregation.metadata.type.value + \"LogicalFile\", aggregation.main_file_path, ) aggregation._hs_session.post(path, status_code=200) aggregation.refresh()","title":"aggregation_remove()"},{"location":"api/resource/#hsclient.hydroshare.Resource.copy","text":"Copies this Resource into a new resource on HydroShare returns: A Resource object of the newly copied resource Source code in hsclient/hydroshare.py def copy(self): \"\"\" Copies this Resource into a new resource on HydroShare returns: A Resource object of the newly copied resource \"\"\" path = urljoin(self._hsapi_path, \"copy\") response = self._hs_session.post(path, status_code=202) resource_id = response.text return Resource(\"/resource/{}/data/resourcemap.xml\".format(resource_id), self._hs_session)","title":"copy()"},{"location":"api/resource/#hsclient.hydroshare.Resource.delete","text":"Deletes the resource on HydroShare :return: None Source code in hsclient/hydroshare.py @refresh def delete(self) -> None: \"\"\" Deletes the resource on HydroShare :return: None \"\"\" hsapi_path = self._hsapi_path self._hs_session.delete(hsapi_path, status_code=204)","title":"delete()"},{"location":"api/resource/#hsclient.hydroshare.Resource.download","text":"Downloads a zipped bagit archive of the resource from HydroShare param save_path: A local path to save the bag to, defaults to the current working directory returns: The relative pathname of the download Source code in hsclient/hydroshare.py def download ( self , save_path : str = \"\" ) -> str : \"\"\" Downloads a zipped bagit archive of the resource from HydroShare param save_path: A local path to save the bag to, defaults to the current working directory returns: The relative pathname of the download \"\"\" return self . _hs_session . retrieve_bag ( self . _hsapi_path , save_path = save_path )","title":"download()"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_aggregate","text":"Aggregate a file to a HydroShare aggregation type. Aggregating files allows you to specify metadata specific to the files associated with the aggregation. To set a FileSet aggregation, include the path to the folder or a file in the folder you would like to create a FileSet aggregation from. :param path: The path to the file to aggregate :param agg_type: The AggregationType to create :param refresh: Defaults True, toggles automatic refreshing of the updated resource in HydroShare :return: The newly created Aggregation object if refresh is True Source code in hsclient/hydroshare.py def file_aggregate ( self , path: str , agg_type: AggregationType , refresh: bool = True ) : \"\"\" Aggregate a file to a HydroShare aggregation type . Aggregating files allows you to specify metadata specific to the files associated with the aggregation . To set a FileSet aggregation , include the path to the folder or a file in the folder you would like to create a FileSet aggregation from . : param path: The path to the file to aggregate : param agg_type: The AggregationType to create : param refresh: Defaults True , toggles automatic refreshing of the updated resource in HydroShare : return : The newly created Aggregation object if refresh is True \"\"\" type_value = agg_type . value data = {} if agg_type == AggregationType . SingleFileAggregation: type_value = ' SingleFile ' if agg_type == AggregationType . FileSetAggregation: relative_path = dirname ( path ) data = { \"folder_path\" : relative_path } url = urljoin ( self . _hsapi_path , \"functions\" , \"set-file-type\" , path , type_value ) self . _hs_session . post ( url , status_code = 201 , data = data ) if refresh: # Only return the newly created aggregation if a refresh is requested self . refresh () return self . aggregation ( file__path = path )","title":"file_aggregate()"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_delete","text":"Delete a file on HydroShare :param path: The path to the file :return: None Source code in hsclient/hydroshare.py @refresh def file_delete(self, path: str = None) -> None: \"\"\" Delete a file on HydroShare :param path: The path to the file :return: None \"\"\" self._delete_file(path)","title":"file_delete()"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_download","text":"Downloads a file from HydroShare :param path: The path to the file :param save_path: The local path to save the file to :param zipped: Defaults to False, set to True to download the file zipped :return: The path to the downloaded file Source code in hsclient/hydroshare.py def file_download ( self , path : str , save_path : str = \"\" , zipped : bool = False ): \"\"\" Downloads a file from HydroShare :param path: The path to the file :param save_path: The local path to save the file to :param zipped: Defaults to False, set to True to download the file zipped :return: The path to the downloaded file \"\"\" if zipped : return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } ) else : return self . _hs_session . retrieve_file ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path )","title":"file_download()"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_rename","text":"Rename a file on HydroShare :param path: The path to the file :param new_path: the renamed path to the file :return: None Source code in hsclient/hydroshare.py @refresh def file_rename(self, path: str, new_path: str) -> None: \"\"\" Rename a file on HydroShare :param path: The path to the file :param new_path: the renamed path to the file :return: None \"\"\" rename_path = urljoin(self._hsapi_path, \"functions\", \"move-or-rename\") self._hs_session.post(rename_path, status_code=200, data={\"source_path\": path, \"target_path\": new_path})","title":"file_rename()"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_unzip","text":"Unzips a file on HydroShare :param path: The path to the file to unzip :param overwrite: Defaults to True, set to False to unzip the files into a folder with the zip filename :param ingest_metadata: Defaults to True, set to False to not ingest HydroShare RDF metadata xml files :return: None Source code in hsclient/hydroshare.py @refresh def file_unzip(self, path: str, overwrite: bool = True, ingest_metadata=True) -> None: \"\"\" Unzips a file on HydroShare :param path: The path to the file to unzip :param overwrite: Defaults to True, set to False to unzip the files into a folder with the zip filename :param ingest_metadata: Defaults to True, set to False to not ingest HydroShare RDF metadata xml files :return: None \"\"\" if not path.endswith(\".zip\"): raise Exception(\"File {} is not a zip, and cannot be unzipped\".format(path)) unzip_path = urljoin(self._hsapi_path, \"functions\", \"unzip\", \"data\", \"contents\", path) self._hs_session.post( unzip_path, status_code=200, data={\"overwrite\": overwrite, \"ingest_metadata\": ingest_metadata} )","title":"file_unzip()"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_upload","text":"Uploads files to a folder in HydroShare :param *files: The local file paths to upload :param destination_path: The path on HydroShare to upload the files to, defaults to the root contents directory :return: None Source code in hsclient/hydroshare.py @ refresh def file_upload ( self , * files : str , destination_path : str = \"\" ) -> None : \"\"\" Uploads files to a folder in HydroShare :param *files: The local file paths to upload :param destination_path: The path on HydroShare to upload the files to, defaults to the root contents directory :return: None \"\"\" if len ( files ) == 1 : self . _upload ( files [ 0 ], destination_path = destination_path ) else : with tempfile . TemporaryDirectory () as tmpdir : zipped_file = os . path . join ( tmpdir , 'files.zip' ) with ZipFile ( zipped_file , 'w' ) as zipped : for file in files : zipped . write ( file , os . path . basename ( file )) self . _upload ( zipped_file , destination_path = destination_path ) unzip_path = urljoin ( self . _hsapi_path , \"functions\" , \"unzip\" , \"data\" , \"contents\" , destination_path , 'files.zip' ) self . _hs_session . post ( unzip_path , status_code = 200 , data = { \"overwrite\" : \"true\" , \"ingest_metadata\" : \"true\" } )","title":"file_upload()"},{"location":"api/resource/#hsclient.hydroshare.Resource.file_zip","text":"Zip a file on HydroShare :param path: The path to the file :param zip_name: The name of the zipped file :param remove_file: Defaults to True, set to False to not delete the file that was zipped :return: None Source code in hsclient/hydroshare.py @refresh def file_zip(self, path: str, zip_name: str = None, remove_file: bool = True) -> None: \"\"\" Zip a file on HydroShare :param path: The path to the file :param zip_name: The name of the zipped file :param remove_file: Defaults to True, set to False to not delete the file that was zipped :return: None \"\"\" zip_name = basename(path) + \".zip\" if not zip_name else zip_name data = {\"input_coll_path\": path, \"output_zip_file_name\": zip_name, \"remove_original_after_zip\": remove_file} zip_path = urljoin(self._hsapi_path, \"functions\", \"zip\") self._hs_session.post(zip_path, status_code=200, data=data)","title":"file_zip()"},{"location":"api/resource/#hsclient.hydroshare.Resource.folder_create","text":"Creates a folder on HydroShare :param folder: the folder path to create :return: None Source code in hsclient/hydroshare.py @refresh def folder_create(self, folder: str) -> None: \"\"\" Creates a folder on HydroShare :param folder: the folder path to create :return: None \"\"\" path = urljoin(self._hsapi_path, \"folders\", folder) self._hs_session.put(path, status_code=201)","title":"folder_create()"},{"location":"api/resource/#hsclient.hydroshare.Resource.folder_delete","text":"Deletes a folder on HydroShare :param path: the path to the folder :return: None Source code in hsclient/hydroshare.py @refresh def folder_delete(self, path: str = None) -> None: \"\"\" Deletes a folder on HydroShare :param path: the path to the folder :return: None \"\"\" self._delete_file_folder(path)","title":"folder_delete()"},{"location":"api/resource/#hsclient.hydroshare.Resource.folder_download","text":"Downloads a folder from HydroShare :param path: The path to folder :param save_path: The local path to save the download to, defaults to the current directory :return: The path to the download zipped folder Source code in hsclient/hydroshare.py def folder_download ( self , path : str , save_path : str = \"\" ): \"\"\" Downloads a folder from HydroShare :param path: The path to folder :param save_path: The local path to save the download to, defaults to the current directory :return: The path to the download zipped folder \"\"\" return self . _hs_session . retrieve_zip ( urljoin ( self . _resource_path , \"data\" , \"contents\" , path ), save_path , params = { \"zipped\" : \"true\" } )","title":"folder_download()"},{"location":"api/resource/#hsclient.hydroshare.Resource.folder_rename","text":"Renames a folder on HydroShare :param path: the path to the folder to rename :param new_path: the new path folder name :return: None Source code in hsclient/hydroshare.py @refresh def folder_rename(self, path: str, new_path: str) -> None: \"\"\" Renames a folder on HydroShare :param path: the path to the folder to rename :param new_path: the new path folder name :return: None \"\"\" self.file_rename(path=path, new_path=new_path)","title":"folder_rename()"},{"location":"api/resource/#hsclient.hydroshare.Resource.new_version","text":"Creates a new version of the resource on HydroShare :return: A Resource object of the newly created resource version Source code in hsclient/hydroshare.py def new_version(self): \"\"\" Creates a new version of the resource on HydroShare :return: A Resource object of the newly created resource version \"\"\" path = urljoin(self._hsapi_path, \"version\") response = self._hs_session.post(path, status_code=202) resource_id = response.text return Resource(\"/resource/{}/data/resourcemap.xml\".format(resource_id), self._hs_session)","title":"new_version()"},{"location":"api/resource/#hsclient.hydroshare.Resource.reference_create","text":"Creates a HydroShare reference object to reference content outside of the resource :param file_name: the file name of the resulting .url file :param url: the url of the referenced content :param path: the path to create the reference in :return: None Source code in hsclient/hydroshare.py @refresh def reference_create(self, file_name: str, url: str, path: str = '') -> None: \"\"\" Creates a HydroShare reference object to reference content outside of the resource :param file_name: the file name of the resulting .url file :param url: the url of the referenced content :param path: the path to create the reference in :return: None \"\"\" request_path = urljoin(self._hsapi_path.replace(self.resource_id, \"\"), \"data-store-add-reference\") self._hs_session.post( request_path, data={\"res_id\": self.resource_id, \"curr_path\": path, \"ref_name\": file_name, \"ref_url\": url}, status_code=200, )","title":"reference_create()"},{"location":"api/resource/#hsclient.hydroshare.Resource.reference_update","text":"Updates a HydroShare reference object :param file_name: the file name for the .url file :param url: the url of the referenced content :param path: the path to the directory where the reference is located :return: None Source code in hsclient/hydroshare.py @refresh def reference_update(self, file_name: str, url: str, path: str = '') -> None: \"\"\" Updates a HydroShare reference object :param file_name: the file name for the .url file :param url: the url of the referenced content :param path: the path to the directory where the reference is located :return: None \"\"\" request_path = urljoin(self._hsapi_path.replace(self.resource_id, \"\"), \"data_store_edit_reference_url\") self._hs_session.post( request_path, data={\"res_id\": self.resource_id, \"curr_path\": path, \"url_filename\": file_name, \"new_ref_url\": url}, status_code=200, )","title":"reference_update()"},{"location":"api/resource/#hsclient.hydroshare.Resource.save","text":"Saves the metadata to HydroShare :return: None Source code in hsclient/hydroshare.py @ refresh def save ( self ) -> None : \"\"\" Saves the metadata to HydroShare :return: None \"\"\" metadata_string = rdf_string ( self . _retrieved_metadata , rdf_format = \"xml\" ) path = urljoin ( self . _hsapi_path , \"ingest_metadata\" ) self . _hs_session . upload_file ( path , files = { 'file' : ( 'resourcemetadata.xml' , metadata_string )})","title":"save()"},{"location":"api/resource/#hsclient.hydroshare.Resource.set_sharing_status","text":"Set the sharing status of the resource to public or private :param public: bool, set to True for public, False for private Source code in hsclient/hydroshare.py def set_sharing_status(self, public: bool): \"\"\" Set the sharing status of the resource to public or private :param public: bool, set to True for public, False for private \"\"\" path = urljoin(\"hsapi\", \"resource\", \"accessRules\", self.resource_id) data = {'public': public} self._hs_session.put(path, status_code=200, data=data)","title":"set_sharing_status()"},{"location":"api/resource/#hsclient.hydroshare.Resource.system_metadata","text":"The system metadata associated with the HydroShare resource returns: JSON object Source code in hsclient/hydroshare.py def system_metadata(self): \"\"\" The system metadata associated with the HydroShare resource returns: JSON object \"\"\" hsapi_path = urljoin(self._hsapi_path, 'sysmeta') return self._hs_session.get(hsapi_path, status_code=200).json()","title":"system_metadata()"},{"location":"examples/Aggregation_Operations/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); HS RDF HydroShare Python Client Resource Aggregation Operation Examples The following code snippets show examples for how to use the HS RDF HydroShare Python Client to manipulate aggregations of known content types in HydroShare. HydroShare's content type aggregations include individual file, fileset, time series, geographic feature, geographic raster, and multidimensional NetCDF. Install the HS RDF Python Client The HS RDF Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. ! pip install hsclient Authenticating with HydroShare Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare () hs . sign_in () Create a New Empty Resource A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs . create () # Get the HydroShare identifier for the new resource resIdentifier = new_resource . resource_id print ( 'The HydroShare Identifier for your new resource is: ' + resIdentifier ) # Construct a hyperlink for the new resource print ( 'Your new resource is available at: ' + new_resource . metadata . url ) Resource Aggregation Handling HydroShare allows you to create and manage aggregations of content files within resources that have specific types and associated metadata. These known content types include: Time series Geographic feature Geographic raster Multidimensional NetCDF Single file File set The general process for creating an aggregation within a resource requires adding files to the resource and then applying the appropriate aggregation type. For some of the aggregation types, some of the aggregation metadata fields will be automatically extracted from the files you upload. You can then set the values of the other aggregation-level metadata elements. Create a Single File Aggregation A single file aggregation in a HydroShare is any individual file to which you want to add extra metadata. # Import the aggregation types from hsmodels.schemas.enums import AggregationType # Upload a single content file to the resource. This is a generic sample comma separated # values (CSV) data file with some tabular data new_resource . file_upload ( 'Example_Files/Data_File1.csv' ) # Specify the file you want to add the aggregation to file = new_resource . file ( path = \"Data_File1.csv\" ) # Create a single file aggregation on the file and refresh the resource agg = new_resource . file_aggregate ( file , AggregationType . SingleFileAggregation ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type ) Add Metadata to the Aggregation Once you have created an aggregation, you can edit and add metadata elements. For a single file aggregation, you can add a title, subject keywords, extended metadata as key-value pairs, and spatial and temporal coverage. All of the metadata edits are stored locally until you call the save() function on the aggregation to write the edits you have made to HydroShare. Title and Keywords The title of an aggregation is a string. Subject keywords are handled as a list of strings. # Set the title and subject keywords for the aggregation agg . metadata . title = \"A CSV Data File Single File Aggregation\" agg . metadata . subjects = [ 'CSV' , 'Aggregation' , 'Single File' , 'Data' ] # Print the title and keywords for the aggregation print ( 'Aggregation Title: ' + agg . metadata . title ) print ( 'Aggregation Keywords: ' + ', ' . join ( agg . metadata . subjects )) # Save the aggregation to write all of the metadata to HydroShare agg . save () Extended Metadata Elements Extended metadata elements for an aggregation are handled using a Python dictionary. You can add new elements using key-value pairs. # Add an extended metadata element to the aggregation as a key-value pair agg . metadata . additional_metadata [ 'New Element Key' ] = 'Text value of new element.' # Remove an individual key-value pair from the aggregation using its key del agg . metadata . additional_metadata [ 'New Element Key' ] # Or, you can clear out all of the extended metadata elements that might exist agg . metadata . additional_metadata . clear () # Add multiple key-value pairs to the aggregation at once using a Python dictionary agg . metadata . additional_metadata = { 'Observed Variable' : 'Water use' , 'Site Location' : 'Valley View Tower Dormatory on Utah State University \\' s Campus in Logan, UT' } # Print the extended metadata elements print ( 'The extended metadata elements for the aggregation include:' ) for key , value in agg . metadata . additional_metadata . items (): print ( key + ':' , value ) # Save the aggregation to write all of the metadata to HydroShare agg . save () Spatial and Temporal Coverage Spatial and temporal coverage for an aggregation are handled in the same way they are handled for resource level metadata. Initially the spatial and temporal coverage for an aggregation are empty. To set them, you have to create a coverage object of the right type and set the spatial or temporal coverage to that object. # Import the required metadata classes for coverage objects from hsmodels.schemas.fields import BoxCoverage , PointCoverage , PeriodCoverage from datetime import datetime # Set the spatial coverage of the aggregation to a BoxCoverage object agg . metadata . spatial_coverage = BoxCoverage ( name = 'Logan, Utah' , northlimit = 41.7910 , eastlimit =- 111.7664 , southlimit = 41.6732 , westlimit =- 111.9079 , projection = 'WGS 84 EPSG:4326' , type = 'box' , units = 'Decimal degrees' ) # You can remove the spatial coverage element by setting it to None agg . metadata . spatial_coverage = None # If you want to set the spatial coverage to a PointCoverage instead agg . metadata . spatial_coverage = PointCoverage ( name = 'Logan, Utah' , north = 41.7371 , east =- 111.8351 , projection = 'WGS 84 EPSG:4326' , type = 'point' , units = 'Decimal degrees' ) # Create a beginning and ending date for a time period beginDate = datetime . strptime ( '2020-12-01T00:00:00Z' , '%Y-%m- %d T%H:%M:%S %f Z' ) endDate = datetime . strptime ( '2020-12-31T00:00:00Z' , '%Y-%m- %d T%H:%M:%S %f Z' ) # Set the temporal coverage of the aggregation to a PeriodCoverage object agg . metadata . period_coverage = PeriodCoverage ( start = beginDate , end = endDate ) # Print the temporal coverage information print ( 'Temporal Coverage' ) print ( agg . metadata . period_coverage ) # Print the spatial coverage information print ( ' \\n Spatial Coverage' ) print ( agg . metadata . spatial_coverage ) # Save the aggregation to write all of the metadata to HydroShare agg . save () Creating Other Aggregation Types Geographic Feature Aggregation Geographic feature aggregations are created in HydroShare from the set of files that make up an ESRI Shapefile. You need to upload the shapefile and then HydroShare will automatically set the aggregation on the set of files you upload. You can then retrieve the aggregation using its title or by searching for one of the files it contains. # Create a list of the files that make up the shapefile to be uploaded file_list = [ 'Example_Files/watersheds.cpg' , 'Example_Files/watersheds.dbf' , 'Example_Files/watersheds.prj' , 'Example_Files/watersheds.sbn' , 'Example_Files/watersheds.sbx' , 'Example_Files/watersheds.shp' , 'Example_Files/watersheds.shx' , 'Example_Files/watersheds.shp.xml' ] # Upload the files to the resource all at the same time new_resource . file_upload ( * file_list ) print ( 'Files uploaded!' ) If you upload all of the files of a shapefile together as shown above, HydroShare automatically recognizes the files as a shapefile and auto-aggregates the files into a geographic feature aggregation for you. So, you then just need to get the aggregation that was created if you want to further operate on it - e.g., to modify the aggregation-level metadata. Metadata for a geographic feature aggregation includes a title, subject keywords, extended key-value pairs, temporal coverage, spatial coverage, geometry information, spatial reference, and field information. When HydroShare creates the aggregation on the shapefile, the spatial coverage, geometry information, spatial reference, and attribute field information metadata will be automatically set for you. You can then set all of the other metadata elements as shown above for the single file aggregation if you need to. # Get the aggregation that was just created # You can get the aggregation by searching for a file that is inside of it agg = new_resource . aggregation ( file__name = \"watersheds.shp\" ) # Or, you can get the aggregation by searching for its title, which is initially # set to the name of the shapefile agg = new_resource . aggregation ( title = \"watersheds\" ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type ) Geographic Raster Aggregation Geographic raster aggregations are created in HydroShare from one or more raster data files that make up a raster dataset. HydroShare uses GeoTiff files for raster datasets. Like the geographic feature aggregation, when you upload all of the files for a geographic raster dataset (all .tif and a .vrt file) at once, HydroShare will automatically create the aggregation for you. You can then get the aggregation and set the other metadata elements as shown above for the single file aggregation. HydroShare initially sets the title of the geographic raster aggregation to the first .tif file that appears in the .vrt file. The spatial coverage, spatial reference, and cell information are set automatically based on information extracted from the dataset. # Upload the files making up the raster dataset to the resource file_list = [ 'Example_Files/logan1.tif' , 'Example_Files/logan2.tif' , 'Example_Files/logan.vrt' ] new_resource . file_upload ( * file_list ) # Get the aggregation that was just created - initially the title will be \"logan1\" # based on the name of the first .tif file that appears in the .vrt file agg = new_resource . aggregation ( title = \"logan1\" ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type ) Multidimensional NetCDF Aggregation Multidimensional aggregations are created in HydroShare from a NetCDF file. Like the other aggregation types, you can upload the NetCDF file and HydroShare will automatically create the aggregation for you. HydroShare also automatically extracts metadata from the NetCDF file to populate the aggregation metadata. Some of this metadata may get propagated to the resource level if you haven't set things like the title and keywords. You can then get the aggregation and set the other metadata elements as shown above for the single file aggregation. # Upload the NetCDF file to the resource new_resource . file_upload ( 'Example_Files/SWE_time.nc' ) # Get the aggregation by searching for the NetCDF file that is inside of it agg = new_resource . aggregation ( file__name = \"SWE_time.nc\" ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type ) Time Series Aggregation Time series aggregations are created in HydroShare from an ODM2 SQLite database file. The ODM2 SQLite database contain one or more time series # Upload the SQLite file to the resource new_resource . file_upload ( 'Example_Files/ODM2.sqlite' ) # Get the aggregation by searching for the SQLite file that is inside of it agg = new_resource . aggregation ( file__name = \"ODM2.sqlite\" ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type ) File Set Aggregation A file set aggregation is any folder within a resource to which you want to add metadata. If you want to create a file set aggregation, you first have to create a folder, then upload files to it. After that, you can set the aggregation on the folder. # Create a new folder for the file set aggregation new_resource . folder_create ( 'Fileset_Aggregation' ) # Add some files to the folder new_resource . file_upload ( 'Example_Files/Data_File1.csv' , 'Example_Files/Data_File2.csv' , destination_path = 'Fileset_Aggregation' ) # TODO: How to set a fileset aggregation on a folder containing files? Get Aggregation Properties Each aggregation in a resource has metadata properties associated with it. You can query/retrieve those properties for display. The following shows an example for the time series aggregation that was created above. # Get the time series aggregation that was created above agg = new_resource . aggregation ( type = \"TimeSeries\" ) # Print the metadata associated with the aggregation print ( 'Aggregation Title: ' + agg . metadata . title ) print ( 'Aggregation Type: ' + agg . metadata . type ) print ( 'Aggregation Keywords: ' + ', ' . join ( agg . metadata . subjects )) print ( 'Aggregation Temporal Coverage: ' + str ( agg . metadata . period_coverage )) print ( 'Aggregation Spatial Coverage: ' + str ( agg . metadata . spatial_coverage )) # Print the list of files in the aggregation file_list = agg . files () print ( 'List of files contained within the aggregation:' ) print ( * file_list , sep = ' \\n ' ) Searching for Aggregations within a Resource If you need to find/get one or more aggregations within a resource so you can download or remove it from the resource, there are several filters available that allow you to return a list of aggregations that meet your search criteria. # Get the list of all aggregations in the resource aggregations = new_resource . aggregations () # Get a list of all aggregations of a particular type aggregations = new_resource . aggregations ( type = \"TimeSeries\" ) # Get a list of aggregations with extended metadata searching by key aggregations = new_resource . aggregations ( additional_metadata__key = \"Observed Variable\" ) # Get a list of aggregations with extended metadata searching by value aggregations = new_resource . aggregations ( additional_metadata__value = \"Water Use\" ) # Get a list of aggregations with a subject keyword searching by value aggregations = new_resource . aggregations ( subjects__contains = \"Temperature\" ) # Get a list of aggregations searching by title (or any metadata attribute) aggregations = new_resource . aggregations ( title = \"watersheds\" ) # Get a list of aggregations searching by a nested metadata attribute (__) aggregations = new_resource . aggregations ( period_coverage__name = \"period_coverage name\" ) # Get a list of aggregations by combining field searching, filtered with \u201cAND\u201d aggrregations = new_resource . aggregations ( period_coverage__name = \"period_coverage name\" , title = \"watersheds\" ) You can also search for individual aggregations within a resource. # Search for an aggregation of type time series aggregation = new_resource . aggregation ( type = \"TimeSeries\" ) # Search for an aggregation with a specific title aggregation = new_resource . aggregation ( title = \"watersheds\" ) # Search for an aggregation that contains a particular file name aggregation = new_resource . aggregation ( file__name = \"ODM2.sqlite\" ) Downloading an Aggregation When working with a resource, you may want to download one of the aggregations contained within the resource. If you want to download it to a particular location on your disk, you can pass a path to the location where you want the aggregation to be saved to the download() function as a string. Aggregations are downloaded as a zipped file containing the aggregation content and metadata files. # Get the geographic feature aggregation that was created above agg = new_resource . aggregation ( title = \"watersheds\" ) # Download the aggregation new_resource . aggregation_download ( agg ) Clean up the zippled aggregation file that was just downloaded. ! rm 'watersheds.shp.zip' Remove and Delete an Aggregation You may wish to remove an aggregation from a resource. There are two functions you can use to do this. The difference between the two is whether the aggregation's content files are preserved in the resource or deleted. To remove the aggregation-specific metadata and associations while maintaining the content files, call the remove() function on the aggregation. # Get the geographic raster aggregation that was created above agg = new_resource . aggregation ( title = \"logan1\" ) # Remove the aggregation and delete its metadata, but leave the file(s) new_resource . aggregation_remove ( agg ) If you want to delete the aggregation, including its metadata and the associated content files, you can call the delete() function on the aggregation. Once you have called the remove() function on an aggregation, the delete() function will no longer work and you will have to delete the files individually. # Get the multidimensional NetCDF aggregation that was created above agg = new_resource . aggregation ( type = \"NetCDF\" ) # Delete the aggregation and metadata along with files within aggregation new_resource . aggregation_delete ( agg )","title":"Aggregation Operations"},{"location":"examples/Aggregation_Operations/#hs-rdf-hydroshare-python-client-resource-aggregation-operation-examples","text":"The following code snippets show examples for how to use the HS RDF HydroShare Python Client to manipulate aggregations of known content types in HydroShare. HydroShare's content type aggregations include individual file, fileset, time series, geographic feature, geographic raster, and multidimensional NetCDF.","title":"HS RDF HydroShare Python Client Resource Aggregation Operation Examples"},{"location":"examples/Aggregation_Operations/#install-the-hs-rdf-python-client","text":"The HS RDF Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. ! pip install hsclient","title":"Install the HS RDF Python Client"},{"location":"examples/Aggregation_Operations/#authenticating-with-hydroshare","text":"Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare () hs . sign_in ()","title":"Authenticating with HydroShare"},{"location":"examples/Aggregation_Operations/#create-a-new-empty-resource","text":"A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs . create () # Get the HydroShare identifier for the new resource resIdentifier = new_resource . resource_id print ( 'The HydroShare Identifier for your new resource is: ' + resIdentifier ) # Construct a hyperlink for the new resource print ( 'Your new resource is available at: ' + new_resource . metadata . url )","title":"Create a New Empty Resource"},{"location":"examples/Aggregation_Operations/#resource-aggregation-handling","text":"HydroShare allows you to create and manage aggregations of content files within resources that have specific types and associated metadata. These known content types include: Time series Geographic feature Geographic raster Multidimensional NetCDF Single file File set The general process for creating an aggregation within a resource requires adding files to the resource and then applying the appropriate aggregation type. For some of the aggregation types, some of the aggregation metadata fields will be automatically extracted from the files you upload. You can then set the values of the other aggregation-level metadata elements.","title":"Resource Aggregation Handling"},{"location":"examples/Aggregation_Operations/#create-a-single-file-aggregation","text":"A single file aggregation in a HydroShare is any individual file to which you want to add extra metadata. # Import the aggregation types from hsmodels.schemas.enums import AggregationType # Upload a single content file to the resource. This is a generic sample comma separated # values (CSV) data file with some tabular data new_resource . file_upload ( 'Example_Files/Data_File1.csv' ) # Specify the file you want to add the aggregation to file = new_resource . file ( path = \"Data_File1.csv\" ) # Create a single file aggregation on the file and refresh the resource agg = new_resource . file_aggregate ( file , AggregationType . SingleFileAggregation ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type )","title":"Create a Single File Aggregation"},{"location":"examples/Aggregation_Operations/#add-metadata-to-the-aggregation","text":"Once you have created an aggregation, you can edit and add metadata elements. For a single file aggregation, you can add a title, subject keywords, extended metadata as key-value pairs, and spatial and temporal coverage. All of the metadata edits are stored locally until you call the save() function on the aggregation to write the edits you have made to HydroShare.","title":"Add Metadata to the Aggregation"},{"location":"examples/Aggregation_Operations/#title-and-keywords","text":"The title of an aggregation is a string. Subject keywords are handled as a list of strings. # Set the title and subject keywords for the aggregation agg . metadata . title = \"A CSV Data File Single File Aggregation\" agg . metadata . subjects = [ 'CSV' , 'Aggregation' , 'Single File' , 'Data' ] # Print the title and keywords for the aggregation print ( 'Aggregation Title: ' + agg . metadata . title ) print ( 'Aggregation Keywords: ' + ', ' . join ( agg . metadata . subjects )) # Save the aggregation to write all of the metadata to HydroShare agg . save ()","title":"Title and Keywords"},{"location":"examples/Aggregation_Operations/#extended-metadata-elements","text":"Extended metadata elements for an aggregation are handled using a Python dictionary. You can add new elements using key-value pairs. # Add an extended metadata element to the aggregation as a key-value pair agg . metadata . additional_metadata [ 'New Element Key' ] = 'Text value of new element.' # Remove an individual key-value pair from the aggregation using its key del agg . metadata . additional_metadata [ 'New Element Key' ] # Or, you can clear out all of the extended metadata elements that might exist agg . metadata . additional_metadata . clear () # Add multiple key-value pairs to the aggregation at once using a Python dictionary agg . metadata . additional_metadata = { 'Observed Variable' : 'Water use' , 'Site Location' : 'Valley View Tower Dormatory on Utah State University \\' s Campus in Logan, UT' } # Print the extended metadata elements print ( 'The extended metadata elements for the aggregation include:' ) for key , value in agg . metadata . additional_metadata . items (): print ( key + ':' , value ) # Save the aggregation to write all of the metadata to HydroShare agg . save ()","title":"Extended Metadata Elements"},{"location":"examples/Aggregation_Operations/#spatial-and-temporal-coverage","text":"Spatial and temporal coverage for an aggregation are handled in the same way they are handled for resource level metadata. Initially the spatial and temporal coverage for an aggregation are empty. To set them, you have to create a coverage object of the right type and set the spatial or temporal coverage to that object. # Import the required metadata classes for coverage objects from hsmodels.schemas.fields import BoxCoverage , PointCoverage , PeriodCoverage from datetime import datetime # Set the spatial coverage of the aggregation to a BoxCoverage object agg . metadata . spatial_coverage = BoxCoverage ( name = 'Logan, Utah' , northlimit = 41.7910 , eastlimit =- 111.7664 , southlimit = 41.6732 , westlimit =- 111.9079 , projection = 'WGS 84 EPSG:4326' , type = 'box' , units = 'Decimal degrees' ) # You can remove the spatial coverage element by setting it to None agg . metadata . spatial_coverage = None # If you want to set the spatial coverage to a PointCoverage instead agg . metadata . spatial_coverage = PointCoverage ( name = 'Logan, Utah' , north = 41.7371 , east =- 111.8351 , projection = 'WGS 84 EPSG:4326' , type = 'point' , units = 'Decimal degrees' ) # Create a beginning and ending date for a time period beginDate = datetime . strptime ( '2020-12-01T00:00:00Z' , '%Y-%m- %d T%H:%M:%S %f Z' ) endDate = datetime . strptime ( '2020-12-31T00:00:00Z' , '%Y-%m- %d T%H:%M:%S %f Z' ) # Set the temporal coverage of the aggregation to a PeriodCoverage object agg . metadata . period_coverage = PeriodCoverage ( start = beginDate , end = endDate ) # Print the temporal coverage information print ( 'Temporal Coverage' ) print ( agg . metadata . period_coverage ) # Print the spatial coverage information print ( ' \\n Spatial Coverage' ) print ( agg . metadata . spatial_coverage ) # Save the aggregation to write all of the metadata to HydroShare agg . save ()","title":"Spatial and Temporal Coverage"},{"location":"examples/Aggregation_Operations/#creating-other-aggregation-types","text":"","title":"Creating Other Aggregation Types"},{"location":"examples/Aggregation_Operations/#geographic-feature-aggregation","text":"Geographic feature aggregations are created in HydroShare from the set of files that make up an ESRI Shapefile. You need to upload the shapefile and then HydroShare will automatically set the aggregation on the set of files you upload. You can then retrieve the aggregation using its title or by searching for one of the files it contains. # Create a list of the files that make up the shapefile to be uploaded file_list = [ 'Example_Files/watersheds.cpg' , 'Example_Files/watersheds.dbf' , 'Example_Files/watersheds.prj' , 'Example_Files/watersheds.sbn' , 'Example_Files/watersheds.sbx' , 'Example_Files/watersheds.shp' , 'Example_Files/watersheds.shx' , 'Example_Files/watersheds.shp.xml' ] # Upload the files to the resource all at the same time new_resource . file_upload ( * file_list ) print ( 'Files uploaded!' ) If you upload all of the files of a shapefile together as shown above, HydroShare automatically recognizes the files as a shapefile and auto-aggregates the files into a geographic feature aggregation for you. So, you then just need to get the aggregation that was created if you want to further operate on it - e.g., to modify the aggregation-level metadata. Metadata for a geographic feature aggregation includes a title, subject keywords, extended key-value pairs, temporal coverage, spatial coverage, geometry information, spatial reference, and field information. When HydroShare creates the aggregation on the shapefile, the spatial coverage, geometry information, spatial reference, and attribute field information metadata will be automatically set for you. You can then set all of the other metadata elements as shown above for the single file aggregation if you need to. # Get the aggregation that was just created # You can get the aggregation by searching for a file that is inside of it agg = new_resource . aggregation ( file__name = \"watersheds.shp\" ) # Or, you can get the aggregation by searching for its title, which is initially # set to the name of the shapefile agg = new_resource . aggregation ( title = \"watersheds\" ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type )","title":"Geographic Feature Aggregation"},{"location":"examples/Aggregation_Operations/#geographic-raster-aggregation","text":"Geographic raster aggregations are created in HydroShare from one or more raster data files that make up a raster dataset. HydroShare uses GeoTiff files for raster datasets. Like the geographic feature aggregation, when you upload all of the files for a geographic raster dataset (all .tif and a .vrt file) at once, HydroShare will automatically create the aggregation for you. You can then get the aggregation and set the other metadata elements as shown above for the single file aggregation. HydroShare initially sets the title of the geographic raster aggregation to the first .tif file that appears in the .vrt file. The spatial coverage, spatial reference, and cell information are set automatically based on information extracted from the dataset. # Upload the files making up the raster dataset to the resource file_list = [ 'Example_Files/logan1.tif' , 'Example_Files/logan2.tif' , 'Example_Files/logan.vrt' ] new_resource . file_upload ( * file_list ) # Get the aggregation that was just created - initially the title will be \"logan1\" # based on the name of the first .tif file that appears in the .vrt file agg = new_resource . aggregation ( title = \"logan1\" ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type )","title":"Geographic Raster Aggregation"},{"location":"examples/Aggregation_Operations/#multidimensional-netcdf-aggregation","text":"Multidimensional aggregations are created in HydroShare from a NetCDF file. Like the other aggregation types, you can upload the NetCDF file and HydroShare will automatically create the aggregation for you. HydroShare also automatically extracts metadata from the NetCDF file to populate the aggregation metadata. Some of this metadata may get propagated to the resource level if you haven't set things like the title and keywords. You can then get the aggregation and set the other metadata elements as shown above for the single file aggregation. # Upload the NetCDF file to the resource new_resource . file_upload ( 'Example_Files/SWE_time.nc' ) # Get the aggregation by searching for the NetCDF file that is inside of it agg = new_resource . aggregation ( file__name = \"SWE_time.nc\" ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type )","title":"Multidimensional NetCDF Aggregation"},{"location":"examples/Aggregation_Operations/#time-series-aggregation","text":"Time series aggregations are created in HydroShare from an ODM2 SQLite database file. The ODM2 SQLite database contain one or more time series # Upload the SQLite file to the resource new_resource . file_upload ( 'Example_Files/ODM2.sqlite' ) # Get the aggregation by searching for the SQLite file that is inside of it agg = new_resource . aggregation ( file__name = \"ODM2.sqlite\" ) # Print the title for the aggregation that was added to the resource print ( 'The following aggregation was added to the resource: ' + agg . metadata . title ) print ( 'Aggregation type: ' + agg . metadata . type )","title":"Time Series Aggregation"},{"location":"examples/Aggregation_Operations/#file-set-aggregation","text":"A file set aggregation is any folder within a resource to which you want to add metadata. If you want to create a file set aggregation, you first have to create a folder, then upload files to it. After that, you can set the aggregation on the folder. # Create a new folder for the file set aggregation new_resource . folder_create ( 'Fileset_Aggregation' ) # Add some files to the folder new_resource . file_upload ( 'Example_Files/Data_File1.csv' , 'Example_Files/Data_File2.csv' , destination_path = 'Fileset_Aggregation' ) # TODO: How to set a fileset aggregation on a folder containing files?","title":"File Set Aggregation"},{"location":"examples/Aggregation_Operations/#get-aggregation-properties","text":"Each aggregation in a resource has metadata properties associated with it. You can query/retrieve those properties for display. The following shows an example for the time series aggregation that was created above. # Get the time series aggregation that was created above agg = new_resource . aggregation ( type = \"TimeSeries\" ) # Print the metadata associated with the aggregation print ( 'Aggregation Title: ' + agg . metadata . title ) print ( 'Aggregation Type: ' + agg . metadata . type ) print ( 'Aggregation Keywords: ' + ', ' . join ( agg . metadata . subjects )) print ( 'Aggregation Temporal Coverage: ' + str ( agg . metadata . period_coverage )) print ( 'Aggregation Spatial Coverage: ' + str ( agg . metadata . spatial_coverage )) # Print the list of files in the aggregation file_list = agg . files () print ( 'List of files contained within the aggregation:' ) print ( * file_list , sep = ' \\n ' )","title":"Get Aggregation Properties"},{"location":"examples/Aggregation_Operations/#searching-for-aggregations-within-a-resource","text":"If you need to find/get one or more aggregations within a resource so you can download or remove it from the resource, there are several filters available that allow you to return a list of aggregations that meet your search criteria. # Get the list of all aggregations in the resource aggregations = new_resource . aggregations () # Get a list of all aggregations of a particular type aggregations = new_resource . aggregations ( type = \"TimeSeries\" ) # Get a list of aggregations with extended metadata searching by key aggregations = new_resource . aggregations ( additional_metadata__key = \"Observed Variable\" ) # Get a list of aggregations with extended metadata searching by value aggregations = new_resource . aggregations ( additional_metadata__value = \"Water Use\" ) # Get a list of aggregations with a subject keyword searching by value aggregations = new_resource . aggregations ( subjects__contains = \"Temperature\" ) # Get a list of aggregations searching by title (or any metadata attribute) aggregations = new_resource . aggregations ( title = \"watersheds\" ) # Get a list of aggregations searching by a nested metadata attribute (__) aggregations = new_resource . aggregations ( period_coverage__name = \"period_coverage name\" ) # Get a list of aggregations by combining field searching, filtered with \u201cAND\u201d aggrregations = new_resource . aggregations ( period_coverage__name = \"period_coverage name\" , title = \"watersheds\" ) You can also search for individual aggregations within a resource. # Search for an aggregation of type time series aggregation = new_resource . aggregation ( type = \"TimeSeries\" ) # Search for an aggregation with a specific title aggregation = new_resource . aggregation ( title = \"watersheds\" ) # Search for an aggregation that contains a particular file name aggregation = new_resource . aggregation ( file__name = \"ODM2.sqlite\" )","title":"Searching for Aggregations within a Resource"},{"location":"examples/Aggregation_Operations/#downloading-an-aggregation","text":"When working with a resource, you may want to download one of the aggregations contained within the resource. If you want to download it to a particular location on your disk, you can pass a path to the location where you want the aggregation to be saved to the download() function as a string. Aggregations are downloaded as a zipped file containing the aggregation content and metadata files. # Get the geographic feature aggregation that was created above agg = new_resource . aggregation ( title = \"watersheds\" ) # Download the aggregation new_resource . aggregation_download ( agg ) Clean up the zippled aggregation file that was just downloaded. ! rm 'watersheds.shp.zip'","title":"Downloading an Aggregation"},{"location":"examples/Aggregation_Operations/#remove-and-delete-an-aggregation","text":"You may wish to remove an aggregation from a resource. There are two functions you can use to do this. The difference between the two is whether the aggregation's content files are preserved in the resource or deleted. To remove the aggregation-specific metadata and associations while maintaining the content files, call the remove() function on the aggregation. # Get the geographic raster aggregation that was created above agg = new_resource . aggregation ( title = \"logan1\" ) # Remove the aggregation and delete its metadata, but leave the file(s) new_resource . aggregation_remove ( agg ) If you want to delete the aggregation, including its metadata and the associated content files, you can call the delete() function on the aggregation. Once you have called the remove() function on an aggregation, the delete() function will no longer work and you will have to delete the files individually. # Get the multidimensional NetCDF aggregation that was created above agg = new_resource . aggregation ( type = \"NetCDF\" ) # Delete the aggregation and metadata along with files within aggregation new_resource . aggregation_delete ( agg )","title":"Remove and Delete an Aggregation"},{"location":"examples/Basic_Operations/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); HS RDF HydroShare Python Client Basic Resource Operation Examples The following code snippets show examples for how to use the HS RDF HydroShare Python Client for performing basic resource operations. Install the HS RDF Python Client The HS RDF Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. ! pip install hsclient Authenticating with HydroShare Before you start interacting with resources in HydroShare you will need to authenticate. To authenticate with HydroShare, you can either specify your username and password or you can call the sign_in() function, which will prompt you to input your username and password. from hsclient import HydroShare username = 'username' password = 'password' hs = HydroShare ( username , password ) In most cases you will not want anyone to see your username and password, so you can also call the sign_in() function to be prompted for your username and password. This is better to use if you are sharing a Jupyter Notebook. from hsclient import HydroShare hs = HydroShare () hs . sign_in () Basic Resource Operations Create a New Empty Resource A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs . create () # Get the HydroShare identifier for the new resource resIdentifier = new_resource . resource_id print ( 'The HydroShare Identifier for your new resource is: ' + resIdentifier ) # Construct a hyperlink for the new resource print ( 'Your new resource is available at: ' + new_resource . metadata . url ) Retrieving an Existing Resource If you want to work on an existing resource rather than creating a new one, you can retrieve an existing resource using its HydroShare Identifier. The resource identifier is passed as a string. The resource's metadata is retrieved and loaded into memory. # Get an existing resource using its identifier existing_resource = hs . resource ( resIdentifier ) print ( 'Just retrieved the resource with ID: ' + resIdentifier ) Deleting a Resource If you want to delete a resource you are currently working with, you can just call the delete() function on that resource. This will delete your local copy of the resource and the resource in HydroShare. new_resource . delete () Alternatively, if you know the HydroShare identifier of the resource you want to delete, you can use it to delete the resource. # Delete the resource using its identifier hs . resource ( resIdentifier ) . delete () print ( 'Deleted resource: ' + resIdentifier ) Download an Entire Resource HydroShare allows you to download an entire resource as a zipped file that uses the BagIt packaging standard. You can identify the resource you want to download using its HydroShare identifier. When you call the download() function on the resource, you can pass a path where you want to save the zipped file. Leaving the path blank downloads the files to the directory. This example downloads the HydroShare resource containing these example Jupyter Notebooks. # Get the resource you want to download using its identifier res = hs . resource ( resIdentifier ) # Download the resource as a zipped file. Pass in a file path as a string if you # want to download to a particular location. res . download ()","title":"Basic Operations"},{"location":"examples/Basic_Operations/#hs-rdf-hydroshare-python-client-basic-resource-operation-examples","text":"The following code snippets show examples for how to use the HS RDF HydroShare Python Client for performing basic resource operations.","title":"HS RDF HydroShare Python Client Basic Resource Operation Examples"},{"location":"examples/Basic_Operations/#install-the-hs-rdf-python-client","text":"The HS RDF Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. ! pip install hsclient","title":"Install the HS RDF Python Client"},{"location":"examples/Basic_Operations/#authenticating-with-hydroshare","text":"Before you start interacting with resources in HydroShare you will need to authenticate. To authenticate with HydroShare, you can either specify your username and password or you can call the sign_in() function, which will prompt you to input your username and password. from hsclient import HydroShare username = 'username' password = 'password' hs = HydroShare ( username , password ) In most cases you will not want anyone to see your username and password, so you can also call the sign_in() function to be prompted for your username and password. This is better to use if you are sharing a Jupyter Notebook. from hsclient import HydroShare hs = HydroShare () hs . sign_in ()","title":"Authenticating with HydroShare"},{"location":"examples/Basic_Operations/#basic-resource-operations","text":"","title":"Basic Resource Operations"},{"location":"examples/Basic_Operations/#create-a-new-empty-resource","text":"A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs . create () # Get the HydroShare identifier for the new resource resIdentifier = new_resource . resource_id print ( 'The HydroShare Identifier for your new resource is: ' + resIdentifier ) # Construct a hyperlink for the new resource print ( 'Your new resource is available at: ' + new_resource . metadata . url )","title":"Create a New Empty Resource"},{"location":"examples/Basic_Operations/#retrieving-an-existing-resource","text":"If you want to work on an existing resource rather than creating a new one, you can retrieve an existing resource using its HydroShare Identifier. The resource identifier is passed as a string. The resource's metadata is retrieved and loaded into memory. # Get an existing resource using its identifier existing_resource = hs . resource ( resIdentifier ) print ( 'Just retrieved the resource with ID: ' + resIdentifier )","title":"Retrieving an Existing Resource"},{"location":"examples/Basic_Operations/#deleting-a-resource","text":"If you want to delete a resource you are currently working with, you can just call the delete() function on that resource. This will delete your local copy of the resource and the resource in HydroShare. new_resource . delete () Alternatively, if you know the HydroShare identifier of the resource you want to delete, you can use it to delete the resource. # Delete the resource using its identifier hs . resource ( resIdentifier ) . delete () print ( 'Deleted resource: ' + resIdentifier )","title":"Deleting a Resource"},{"location":"examples/Basic_Operations/#download-an-entire-resource","text":"HydroShare allows you to download an entire resource as a zipped file that uses the BagIt packaging standard. You can identify the resource you want to download using its HydroShare identifier. When you call the download() function on the resource, you can pass a path where you want to save the zipped file. Leaving the path blank downloads the files to the directory. This example downloads the HydroShare resource containing these example Jupyter Notebooks. # Get the resource you want to download using its identifier res = hs . resource ( resIdentifier ) # Download the resource as a zipped file. Pass in a file path as a string if you # want to download to a particular location. res . download ()","title":"Download an Entire Resource"},{"location":"examples/File_Operations/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); HS RDF HydroShare Python Client Resource File Operation Examples The following code snippets show examples for how to use the HS RDF HydroShare Python Client to manipulate files within a HydroShare Resource. Install the HS RDF Python Client The HS RDF Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. ! pip install hsclient Authenticating with HydroShare Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare () hs . sign_in () Create a New Empty Resource A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs . create () # Get the HydroShare identifier for the new resource resIdentifier = new_resource . resource_id print ( 'The HydroShare Identifier for your new resource is: ' + resIdentifier ) # Construct a hyperlink for the new resource print ( 'Your new resource is available at: ' + new_resource . metadata . url ) Resource File Handling HydroShare resources can have any number of files within them organized within a file/directory structure. File handing operations allow you to manage the content files within a resource. First, show the list of files within the resource, which is initially empty. The search_aggregations argument tells the client whether you want to look at all of the files in the resource ( search_aggregations=True ) or if you want to want to only look at files that do not belong to a content aggregation ( search_aggregations=False ). # Print the title of the resource and the list of files it contains print ( 'Working on: ' + new_resource . metadata . title ) print ( 'File list:' ) for file in new_resource . files ( search_aggregations = True ): print ( file . name ) Adding Files to a Resource You may need to add content files to your resource. The examples here upload files from the Example_Files folder that is included with the HydroShare resource that contains these Jupyter Notebook examples. If you are running in your own local Python environment and want to load files from your local machine, you would specify the path to the file(s) on your hard drive. If you want to upload multiple files at once, you can pass multiple file paths separated by commas to the upload() function. Note that if you upload files that already exist, those files will be overwritten. # Upload one or more files to your resource new_resource . file_upload ( 'Example_Files/Data_File1.csv' , 'Example_Files/Data_File2.csv' ) # Print the names of the files in the resource print ( 'Updated file list after adding a file: ' ) for file in new_resource . files ( search_aggregations = True ): print ( file . path ) HydroShare also allows you to create a folder heirarchy within your resource. You can use this functionality to keep your content organized, just as you would on your own computer. You can upload files to specific folders within the resource. Paths to folders are specified relative to the \"content\" directory of the resource. # First create a new folder new_resource . folder_create ( 'New_Folder' ) # Upload one or more files to a specific folder within a resource new_resource . file_upload ( 'Example_Files/Data_File2.csv' , destination_path = 'New_Folder' ) # Print the names of the files in the resource print ( 'Updated file list after adding a file: ' ) for file in new_resource . files ( search_aggregations = True ): print ( file . path ) Searching for Files within a Resource If you need to find/get one or more files within a resource so you can download or remove it from the resource, there are several filters available that allow you to return a list of files that meet your search criteria or a single file. Get a List of Files Execute a filter to return a list of files within the resource that meet the search critera. # Get a list of all of the files in the resource that are not part of an aggregation file_list = new_resource . files () print ( 'All files that are not part of an aggregation:' ) print ( * file_list , sep = ' \\n ' ) print ( ' \\n ' ) # Get a list of all of the files in the resource inclusive of files that are inside # content type aggregations file_list = new_resource . files ( search_aggregations = True ) print ( 'All files in the resource:' ) print ( * file_list , sep = ' \\n ' ) print ( ' \\n ' ) # Get a list of all of the files within a folder in the resource # Note that you have to pass the full relative path to the folder you are searching # because there may be multiple folders within a resource with the same name. # To get files in the root folder, pass an empty string (folder=\"\") file_list = new_resource . files ( folder = \"New_Folder\" ) print ( 'All files within a specific folder:' ) print ( * file_list , sep = ' \\n ' ) print ( ' \\n ' ) # Get a list of all files that have a specific extension. This searches all folders file_list = new_resource . files ( extension = \".csv\" ) print ( 'All files with a .csv file extension:' ) print ( * file_list , sep = ' \\n ' ) print ( ' \\n ' ) # Filters can be combined # Get a list of all files in a particular folder that have a specific extension file_list = new_resource . files ( folder = \"New_Folder\" , extension = \".csv\" ) print ( 'All files with a .csv file extension in a particular folder:' ) print ( * file_list , sep = ' \\n ' ) Search for a Single File Execute a filter to look for a single file in the resource that meets the search critera. # Get a single file using its path relative to the resource content directory file = new_resource . file ( path = \"New_Folder/Data_File2.csv\" ) print ( 'File retrieved using path:' ) print ( file ) print ( ' \\n ' ) # Get a single file using its name # Note that if you have multiple files in your resource with the same name, but in different # folders, you should search for a particular file using the path parameter to ensure that # you get the right file file = new_resource . file ( name = \"Data_File2.csv\" ) print ( 'File retrieved using name:' ) print ( file ) Get the Properties of a File When you use the filters to return a file from a resource, you get back a file object that holds properties of the file. # Search for a file within a resource file = new_resource . file ( path = \"New_Folder/Data_File2.csv\" ) # Print the properties of the file print ( 'File name: ' + file . name ) print ( 'File extension:' + file . extension ) print ( 'File folder name: ' + file . folder ) print ( 'File path: ' + file . path ) print ( 'File url_path: ' + file . url ) #print('File checksum:' + file.checksum) # TODO: The checksum property is not implemented yet Renaming and Moving Files You may need to rename or move files once they have been added to a resource. First get the file object and then rename or move it. # Get a file to rename - use the relative path to the file to make sure you have the right one file = new_resource . file ( path = \"Data_File2.csv\" ) # Rename the file to whatever you want new_resource . file_rename ( file , 'Data_File2_Renamed.csv' ) # Print the names of the files in the resource print ( 'Updated file list after adding a file: ' ) for file in new_resource . files ( search_aggregations = True ): print ( file . path ) Moving files is similar to renaming. Instead of just changing the file name, change the relative path of the file to move it to the new location within the resource. # Get a file to move file = new_resource . file ( path = \"Data_File1.csv\" ) # Move the file to a different folder new_resource . file_rename ( file , 'New_Folder/Data_File1.csv' ) # Print the names of the files in the resource print ( 'Updated file list after adding a file: ' ) for file in new_resource . files ( search_aggregations = True ): print ( file . path ) Downloading Files from a Resource You can download individual files from an existing HydroShare resource. You can use the filters shown above to specify which file(s) you want to download. When you call the download() function on an individual file, you can pass a path where you want to save the file as a string. Leaving the path blank downloads the files to the same directory as your Jupyter Notebook. # Download a single file from a resource # Note that if you have multiple files within the same resource that have the same name, # and you want a particular file, you need to specify the relative path to the specific file file = new_resource . file ( path = 'New_Folder/Data_File1.csv' ) new_resource . file_download ( file ) If you want to, you can clean up the file that was just downloaded by deleting it using a terminal command. ! rm 'Data_File1.csv' Removing Files from a Resource You can also delete files from a resource. In this example, I remove one of the files I added to the resource above. You have to delete each individual file. Make sure you call delete using the path parameter to make sure you are deleting the right file. # Specify the file you want to delete file = new_resource . file ( path = \"New_Folder/Data_File2.csv\" ) new_resource . file_delete ( file ) # Print the names of the files in the resource print ( \"Updated file list after removing file: \" ) for file in new_resource . files ( search_aggregations = True ): print ( file . path ) TODO: The following items are being worked on Delete a folder and all of the files within it. Moving a folder. Zip a file or a folder. Rename a folder. Download a folder as a zipped file.","title":"File Operations"},{"location":"examples/File_Operations/#hs-rdf-hydroshare-python-client-resource-file-operation-examples","text":"The following code snippets show examples for how to use the HS RDF HydroShare Python Client to manipulate files within a HydroShare Resource.","title":"HS RDF HydroShare Python Client Resource File Operation Examples"},{"location":"examples/File_Operations/#install-the-hs-rdf-python-client","text":"The HS RDF Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. ! pip install hsclient","title":"Install the HS RDF Python Client"},{"location":"examples/File_Operations/#authenticating-with-hydroshare","text":"Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare () hs . sign_in ()","title":"Authenticating with HydroShare"},{"location":"examples/File_Operations/#create-a-new-empty-resource","text":"A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs . create () # Get the HydroShare identifier for the new resource resIdentifier = new_resource . resource_id print ( 'The HydroShare Identifier for your new resource is: ' + resIdentifier ) # Construct a hyperlink for the new resource print ( 'Your new resource is available at: ' + new_resource . metadata . url )","title":"Create a New Empty Resource"},{"location":"examples/File_Operations/#resource-file-handling","text":"HydroShare resources can have any number of files within them organized within a file/directory structure. File handing operations allow you to manage the content files within a resource. First, show the list of files within the resource, which is initially empty. The search_aggregations argument tells the client whether you want to look at all of the files in the resource ( search_aggregations=True ) or if you want to want to only look at files that do not belong to a content aggregation ( search_aggregations=False ). # Print the title of the resource and the list of files it contains print ( 'Working on: ' + new_resource . metadata . title ) print ( 'File list:' ) for file in new_resource . files ( search_aggregations = True ): print ( file . name )","title":"Resource File Handling"},{"location":"examples/File_Operations/#adding-files-to-a-resource","text":"You may need to add content files to your resource. The examples here upload files from the Example_Files folder that is included with the HydroShare resource that contains these Jupyter Notebook examples. If you are running in your own local Python environment and want to load files from your local machine, you would specify the path to the file(s) on your hard drive. If you want to upload multiple files at once, you can pass multiple file paths separated by commas to the upload() function. Note that if you upload files that already exist, those files will be overwritten. # Upload one or more files to your resource new_resource . file_upload ( 'Example_Files/Data_File1.csv' , 'Example_Files/Data_File2.csv' ) # Print the names of the files in the resource print ( 'Updated file list after adding a file: ' ) for file in new_resource . files ( search_aggregations = True ): print ( file . path ) HydroShare also allows you to create a folder heirarchy within your resource. You can use this functionality to keep your content organized, just as you would on your own computer. You can upload files to specific folders within the resource. Paths to folders are specified relative to the \"content\" directory of the resource. # First create a new folder new_resource . folder_create ( 'New_Folder' ) # Upload one or more files to a specific folder within a resource new_resource . file_upload ( 'Example_Files/Data_File2.csv' , destination_path = 'New_Folder' ) # Print the names of the files in the resource print ( 'Updated file list after adding a file: ' ) for file in new_resource . files ( search_aggregations = True ): print ( file . path )","title":"Adding Files to a Resource"},{"location":"examples/File_Operations/#searching-for-files-within-a-resource","text":"If you need to find/get one or more files within a resource so you can download or remove it from the resource, there are several filters available that allow you to return a list of files that meet your search criteria or a single file.","title":"Searching for Files within a Resource"},{"location":"examples/File_Operations/#get-a-list-of-files","text":"Execute a filter to return a list of files within the resource that meet the search critera. # Get a list of all of the files in the resource that are not part of an aggregation file_list = new_resource . files () print ( 'All files that are not part of an aggregation:' ) print ( * file_list , sep = ' \\n ' ) print ( ' \\n ' ) # Get a list of all of the files in the resource inclusive of files that are inside # content type aggregations file_list = new_resource . files ( search_aggregations = True ) print ( 'All files in the resource:' ) print ( * file_list , sep = ' \\n ' ) print ( ' \\n ' ) # Get a list of all of the files within a folder in the resource # Note that you have to pass the full relative path to the folder you are searching # because there may be multiple folders within a resource with the same name. # To get files in the root folder, pass an empty string (folder=\"\") file_list = new_resource . files ( folder = \"New_Folder\" ) print ( 'All files within a specific folder:' ) print ( * file_list , sep = ' \\n ' ) print ( ' \\n ' ) # Get a list of all files that have a specific extension. This searches all folders file_list = new_resource . files ( extension = \".csv\" ) print ( 'All files with a .csv file extension:' ) print ( * file_list , sep = ' \\n ' ) print ( ' \\n ' ) # Filters can be combined # Get a list of all files in a particular folder that have a specific extension file_list = new_resource . files ( folder = \"New_Folder\" , extension = \".csv\" ) print ( 'All files with a .csv file extension in a particular folder:' ) print ( * file_list , sep = ' \\n ' )","title":"Get a List of Files"},{"location":"examples/File_Operations/#search-for-a-single-file","text":"Execute a filter to look for a single file in the resource that meets the search critera. # Get a single file using its path relative to the resource content directory file = new_resource . file ( path = \"New_Folder/Data_File2.csv\" ) print ( 'File retrieved using path:' ) print ( file ) print ( ' \\n ' ) # Get a single file using its name # Note that if you have multiple files in your resource with the same name, but in different # folders, you should search for a particular file using the path parameter to ensure that # you get the right file file = new_resource . file ( name = \"Data_File2.csv\" ) print ( 'File retrieved using name:' ) print ( file )","title":"Search for a Single File"},{"location":"examples/File_Operations/#get-the-properties-of-a-file","text":"When you use the filters to return a file from a resource, you get back a file object that holds properties of the file. # Search for a file within a resource file = new_resource . file ( path = \"New_Folder/Data_File2.csv\" ) # Print the properties of the file print ( 'File name: ' + file . name ) print ( 'File extension:' + file . extension ) print ( 'File folder name: ' + file . folder ) print ( 'File path: ' + file . path ) print ( 'File url_path: ' + file . url ) #print('File checksum:' + file.checksum) # TODO: The checksum property is not implemented yet","title":"Get the Properties of a File"},{"location":"examples/File_Operations/#renaming-and-moving-files","text":"You may need to rename or move files once they have been added to a resource. First get the file object and then rename or move it. # Get a file to rename - use the relative path to the file to make sure you have the right one file = new_resource . file ( path = \"Data_File2.csv\" ) # Rename the file to whatever you want new_resource . file_rename ( file , 'Data_File2_Renamed.csv' ) # Print the names of the files in the resource print ( 'Updated file list after adding a file: ' ) for file in new_resource . files ( search_aggregations = True ): print ( file . path ) Moving files is similar to renaming. Instead of just changing the file name, change the relative path of the file to move it to the new location within the resource. # Get a file to move file = new_resource . file ( path = \"Data_File1.csv\" ) # Move the file to a different folder new_resource . file_rename ( file , 'New_Folder/Data_File1.csv' ) # Print the names of the files in the resource print ( 'Updated file list after adding a file: ' ) for file in new_resource . files ( search_aggregations = True ): print ( file . path )","title":"Renaming and Moving Files"},{"location":"examples/File_Operations/#downloading-files-from-a-resource","text":"You can download individual files from an existing HydroShare resource. You can use the filters shown above to specify which file(s) you want to download. When you call the download() function on an individual file, you can pass a path where you want to save the file as a string. Leaving the path blank downloads the files to the same directory as your Jupyter Notebook. # Download a single file from a resource # Note that if you have multiple files within the same resource that have the same name, # and you want a particular file, you need to specify the relative path to the specific file file = new_resource . file ( path = 'New_Folder/Data_File1.csv' ) new_resource . file_download ( file ) If you want to, you can clean up the file that was just downloaded by deleting it using a terminal command. ! rm 'Data_File1.csv'","title":"Downloading Files from a Resource"},{"location":"examples/File_Operations/#removing-files-from-a-resource","text":"You can also delete files from a resource. In this example, I remove one of the files I added to the resource above. You have to delete each individual file. Make sure you call delete using the path parameter to make sure you are deleting the right file. # Specify the file you want to delete file = new_resource . file ( path = \"New_Folder/Data_File2.csv\" ) new_resource . file_delete ( file ) # Print the names of the files in the resource print ( \"Updated file list after removing file: \" ) for file in new_resource . files ( search_aggregations = True ): print ( file . path )","title":"Removing Files from a Resource"},{"location":"examples/File_Operations/#todo-the-following-items-are-being-worked-on","text":"Delete a folder and all of the files within it. Moving a folder. Zip a file or a folder. Rename a folder. Download a folder as a zipped file.","title":"TODO: The following items are being worked on"},{"location":"examples/Metadata_Operations/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); HS RDF HydroShare Python Client Resource Metadata Editing Examples The following code snippets show examples for how to use the HS RDF HydroShare Python Client for creating and editing resource level metadata for a HydroShare resource. Install the HS RDF HydroShare Python Client The HS RDF Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. ! pip install hsclient Authenticate with HydroShare Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare () hs . sign_in () Create a New Empty Resource A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs . create () # Get the HydroShare identifier for the new resource resIdentifier = new_resource . resource_id print ( 'The HydroShare Identifier for your new resource is: ' + resIdentifier ) # Construct a hyperlink for the new resource print ( 'Your new resource is available at: ' + new_resource . metadata . url ) Creating and Editing Resource Metadata Elements Editing metadata elements for a resource can be done in an object oriented way. You can specify all of the metadata elements in code, which will set their values in memory in your local environment. Values of metadata elements can be edited, removed, or replaced by setting them to a new value, appending new values (in the case where the metadata element accepts a list), or by removing the value entirely. When you are ready to save edits to metadata elements from your local environment to the resource in HydroShare, you can call the save() function on your resource and all of the new metadata values you created/edited will be saved to the resource in HydroShare. Resource Title and Abstract The Title and Abstract metadata elements can be specified as text strings. To modify the Title or Abstract after it has been set, just set them to a different value. # Set the Title for the resource new_resource . metadata . title = 'Resource for Testing the HS RDF HydroShare Python Client' # Set the Abstract text for the resource new_resource . metadata . abstract = ( 'This resource was created as a demonstration of using the HS RDF ' 'Python Client for HydroShare. Once you have completed all of the ' 'steps in this notebook, you will have a fully populated HydroShare ' 'Resource.' ) # Call the save function to save the metadata edits to HydroShare new_resource . save () # Print the title just added to the resource print ( 'Title: ' + new_resource . metadata . title ) print ( 'Abstract: ' + new_resource . metadata . abstract ) Subject Keywords Subject keywords can be specified as a Python list of strings. Keywords can be added by creating a list, appending new keywords to the existing list, or by overriding the existing list with a new one. # Create subject keywords for the resource using a list of strings new_resource . metadata . subjects = [ 'HS RDF' , 'Python' , 'HydroShare' , 'Another Keyword' ] # New keywords can be appended to the existing list new_resource . metadata . subjects . append ( 'Hydroinformatics' ) # Keywords can be removed by removing them from the list new_resource . metadata . subjects . remove ( 'Another Keyword' ) # Save the changes to the resource in HydroShare new_resource . save () # Print the keywords for the resource print ( 'The list of keywords for the resource includes:' ) for keyword in new_resource . metadata . subjects : print ( keyword ) Spatial and Temporal Coverage Initially the spatial and temporal coverage for a resource are empty. To set them, you have to create a coverage object of the right type and set the spatial or temporal coverage to that object. # Import the required metadata classes for coverage objects from hsmodels.schemas.fields import BoxCoverage , PointCoverage , PeriodCoverage from datetime import datetime # Set the spatial coverage to a BoxCoverage object new_resource . metadata . spatial_coverage = BoxCoverage ( name = 'Logan, Utah' , northlimit = 41.7910 , eastlimit =- 111.7664 , southlimit = 41.6732 , westlimit =- 111.9079 , projection = 'WGS 84 EPSG:4326' , type = 'box' , units = 'Decimal degrees' ) # You can remove the spatial coverage element by setting it to None new_resource . metadata . spatial_coverage = None # If you want to set the spatial coverage to a PointCoverage instead new_resource . metadata . spatial_coverage = PointCoverage ( name = 'Logan, Utah' , north = 41.7371 , east =- 111.8351 , projection = 'WGS 84 EPSG:4326' , type = 'point' , units = 'Decimal degrees' ) # Create a beginning and ending date for a time period beginDate = datetime . strptime ( '2020-12-01T00:00:00Z' , '%Y-%m- %d T%H:%M:%S %f Z' ) endDate = datetime . strptime ( '2020-12-31T00:00:00Z' , '%Y-%m- %d T%H:%M:%S %f Z' ) # Set the temporal coverage of the resource to a PeriodCoverage object new_resource . metadata . period_coverage = PeriodCoverage ( start = beginDate , end = endDate ) # Save the changes to the resource in HydroShare new_resource . save () # Print the temporal coverage information print ( 'Temporal Coverage' ) print ( new_resource . metadata . period_coverage ) # Print the spatial coverage information print ( ' \\n Spatial Coverage' ) print ( new_resource . metadata . spatial_coverage ) Additional/Extended Metadata HydroShare allows you to create new, extended metadata elements for a HydroShare resource as key-value pairs. You can add new elements, edit existing elements, or remove these elements. Extended metadata elements are stored in the resource as a Python dictionary. # Add an extended metadata element as a key-value pair new_resource . metadata . additional_metadata [ 'New Element Key' ] = 'Text value of new element key.' # Remove an individual key-value pair using its key del new_resource . metadata . additional_metadata [ 'New Element Key' ] # Or, you can clear out all of the additional metadata elements that might exist new_resource . metadata . additional_metadata . clear () # Add multiple key-value pairs at once using a Python dictionary new_resource . metadata . additional_metadata = { 'Observed Variable' : 'Oxygen, dissolved' , 'Site Location' : 'Located on downstream side of river bridge' , 'Observation Depth' : '1 meter' } # Save the changes to the resource in HydroShare new_resource . save () # Print the extended metadata elements for the resource print ( 'The extended metadata elements for the resource include:' ) for key , value in new_resource . metadata . additional_metadata . items (): print ( key + ':' , value ) Sources Sources are stored as a list of strings. Sources can be added or removed by adding or removing source strings from the list. # If you have existing Sources in your resource, you can remove all of them # by clearing the local list and then saving the resource new_resource . metadata . sources . clear () new_resource . save () # Add a Source to the resource sourceString = ( 'Mihalevich, B. A., Horsburgh, J. S., Melcher, A. A. (2017). High-frequency ' 'measurements reveal spatial and temporal patterns of dissolved organic ' 'matter in an urban water conveyance, Environmental Monitoring and ' 'Assessment, http://dx.doi.org/10.1007/s10661-017-6310-y.' ) new_resource . metadata . sources . append ( sourceString ) # Save the changes to the resource in HydroShare new_resource . save () # Print the Source metadata print ( 'The list of Sources includes:' ) for source in new_resource . metadata . sources : print ( source ) Related Resources Related Resources are specified using a string that encodes the citation for the Related Resource along with a relationship type. Because of this, Related Resources are stored as a list of Relation objects. To create a new Related Resource, you have to first instantiate a Relation object and then add it to the list of Related Resources. # Import the required metadata class for a Relation object from hsmodels.schemas.fields import Relation from hsmodels.schemas.enums import RelationType # If you have existing Related Resources, you can remove all of them # by clearing the local list and then saving the resource new_resource . metadata . relations . clear () new_resource . save () # Create a new relation object newRelation = Relation ( type = RelationType . isDataFor , value = ( 'Bastidas Pacheco, C. J., Horsburgh, J. S., Tracy, ' 'R. J. (2020). A low-cost, open source monitoring ' 'system for collecting high-resolution water use ' 'data on magnetically-driven residential water ' 'meters, Sensors, 20(13), 3655, ' 'https://doi.org/10.3390/s20133655.' )) # Append the new Related Resource to the list of Related Resources new_resource . metadata . relations . append ( newRelation ) # Save the changes to the resource in HydroShare new_resource . save () # Print the list of Related Resources print ( 'The list of Related Resources includes:' ) for relatedResource in new_resource . metadata . relations : print ( relatedResource . type . value + ': ' + relatedResource . value ) Funding Agency Credits Funding agency information contains multiple attributes when you add a funding agency to a HydroShare resource. You can create multiple funding agency entries for a resource, which get stored as a Python list. # Import the required metadata class for an AwardInfo object from hsmodels.schemas.fields import AwardInfo # If you have existing funding agency information, you can remove all of them # by clearing the local list and then saving the resource new_resource . metadata . awards . clear () new_resource . save () # Create a new AwardInfo object newAwardInfo = AwardInfo ( funding_agency_name = 'National Science Foundation' , title = ( 'Collaborative Research: Elements: Advancing Data Science ' 'and Analytics for Water (DSAW)' ), number = 'OAC 1931297' , funding_agency_url = 'https://www.nsf.gov/awardsearch/showAward?AWD_ID=1931297' ) # Append the new AwardInfo object to the list of funding agencies new_resource . metadata . awards . append ( newAwardInfo ) # Save the changes to the resource in HydroShare new_resource . save () # Print the AwardInfo print ( 'Funding sources added: ' ) for award in new_resource . metadata . awards : print ( 'Award Title: ' + award . title ) Authors In HydroShare, an \"Author\" is the same as the Dublin Core metadata \"Creator\" element. The Creator element is a list of creators for the resource. However, the order of the Creators matters. When setting Creator information for the resource, you need to edit the local list of creators so that it reflects the order you want. When you call the save() function on the resource, the Creator information in HydroShare will be updated to match what you set locally. To add a new Creator to the list of Creators, you must first instantiate a Creator object and then add it to the list of Creators for the resource. Creator objects can be created by supplying all of the Creator metadata or by copying from a HydroShare user's profile. # Import the required metadata class for a Creator object from hsmodels.schemas.fields import Creator # Instantiate a new Creator object for a Creator that is a HydroShare user newCreator1 = Creator ( name = 'Jones, Amber Spackman' , organization = 'Utah State University' , email = 'amber.jones@usu.edu' , description = '/user/510/' ) # Append the new Creator to the resource's list of Creators new_resource . metadata . creators . append ( newCreator1 ) # Instantiate a new Creator object for a Creator that is not a HydroShare user newCreator2 = Creator ( name = 'Doe, John A.' , organization = 'Utah Water Research Laboratory' , email = 'john.doe@usu.edu' , address = '8200 Old Main Hill, Logan, UT 84322-8200' , phone = '123-456-7890' ) # Append the new Creator to the resource's list of Creators new_resource . metadata . creators . append ( newCreator2 ) # Instantiate a new Creator object for a Creator that is an organization newCreator3 = Creator ( organization = 'Utah Water Research Laboratory' , email = 'uwrl.receptionist@usu.edu' , address = '8200 Old Main Hill, Logan, UT 84322-8200' , homepage = 'http://uwrl.usu.edu' , phone = '435-797-3168 ' ) # Append the new Creator to the resource's list of Creators new_resource . metadata . creators . append ( newCreator3 ) # Instantiate a new Creator object using a HydroShare user object # First, retrieve HydroShare user object tony = hs . user ( 11 ) # Generate a Creator object from a HydroShare user object and append # the new Creator to the resource's list of Creators newCreator4 = Creator . from_user ( tony ) new_resource . metadata . creators . append ( newCreator4 ) # Save the changes to the resource in HydroShare new_resource . save () # Print the Creator names print ( 'The list of Creators includes: ' ) for creator in new_resource . metadata . creators : if creator . name is None : print ( creator . organization ) else : print ( creator . name ) The previous step leaves the resource with a list of 5 Creators. The order in which Creators appear in the metadata and on the Resource Landing Page is controlled by the order in which they appear in the the Creator list. To update the Creator order, update the order of the Creator list and then save the resource. # Change the order of the Creators in the list creatorOrder = [ 3 , 2 , 0 , 1 , 4 ] new_resource . metadata . creators = [ new_resource . metadata . creators [ i ] for i in creatorOrder ] # Save the changes to the resource in HydroShare new_resource . save () # Print the modified order of the Creator names print ( 'The list of Creators includes: ' ) for creator in new_resource . metadata . creators : if creator . name is None : print ( creator . organization ) else : print ( creator . name ) Creators can be removed by removing them from the local list of creators and then calling the save() function on the resource. Note that there must always be at least one creator. # Example of removing all but the first creator del new_resource . metadata . creators [ 1 :] new_resource . save () print ( 'Number of remaining creators: ' + str ( len ( new_resource . metadata . creators ))) Contributors Contributors can be existing HydroShare users or others who do not have HydroShare accounts. Creating and removing contributors is similar to how Creators are handled. Contributors do not have a designated order. # Import the required metadata class for a Contributor object from hsmodels.schemas.fields import Contributor # Instantiate a new Contributor object for a Contributor that is not a HydroShare user newContributor1 = Contributor ( name = 'Horsburgh, Jeffery S.' , organization = 'Utah State University' , email = 'jeff.horsburgh@usu.edu' , phone = '(435) 797-2946' , ORCID = 'https://orcid.org/0000-0002-0768-3196' , address = 'Utah, US' , google_scholar_id = 'https://scholar.google.com/citations?user=mu4k534AAAAJ&hl=en' , homepage = 'http://jeffh.usu.edu' , research_gate_id = 'https://www.researchgate.net/profile/Jeffery_Horsburgh' ) # Append the new Contributor to the resource's list of Contributors new_resource . metadata . contributors . append ( newContributor1 ) # Instantiate a new Contributor object for a Contributor that is not a HydroShare user # Not all of the available metadata for a contributor have to be filled out newContributor2 = Contributor ( name = 'Doe, John A.' , organization = 'Utah State University' , email = 'john.doe@usu.edu' ) # Append the new Contributor to the resource's list of Contributors new_resource . metadata . contributors . append ( newContributor2 ) # Instantiate a new Contributor object using a HydroShare user object # First, retrieve HydroShare user object tony = hs . user ( 11 ) # Generate a Contributor object from the HydroShare user object newContributor3 = Contributor . from_user ( tony ) new_resource . metadata . contributors . append ( newContributor3 ) # Save the changes to the resource in HydroShare new_resource . save () # Print the Contributor names print ( 'The list of Contributors includes: ' ) for Contributor in new_resource . metadata . contributors : print ( Contributor . name ) Similar to other elements, if you want to remove Contributors, you can modify the local list of Creators and then call the save() function on the resource to save the changes in HydroShare. # Clear the list of Contributors and save to HydroShare new_resource . metadata . contributors . clear () new_resource . save () print ( 'Number of remaining Contributors: ' + str ( len ( new_resource . metadata . contributors ))) License and Rights Statement The license under which a Resource is shared can be modified. HydroShare defaults to one of the Creative Commons licenses, but you can change it to a license that meets your needs. The license consists of a rights statement stored as as string and a URL that is a link to a description of the license on the Internet. # Import the required metadata class for a Rights object from hsmodels.schemas.fields import Rights # Set the rights statement and the URL that points to its description new_resource . metadata . rights . statement = ( 'This resource is shared under the Creative Commons ' 'Attribution-NoCommercial-NoDerivs CC BY-NC-ND.' ) new_resource . metadata . rights . url = 'http://creativecommons.org/licenses/by-nc-nd/4.0/' # Save the changes to the resource in HydroShare new_resource . save () # Print the rights statement: print ( new_resource . metadata . rights . statement ) print ( new_resource . metadata . rights . url ) # You can also use one of the available, pre-generated Rights Statements # available in HydroShare new_resource . metadata . rights = Rights . Creative_Commons_Attribution_CC_BY () new_resource . save () # Print the rights statement: print ( new_resource . metadata . rights . statement ) print ( new_resource . metadata . rights . url )","title":"Metadata Operations"},{"location":"examples/Metadata_Operations/#hs-rdf-hydroshare-python-client-resource-metadata-editing-examples","text":"The following code snippets show examples for how to use the HS RDF HydroShare Python Client for creating and editing resource level metadata for a HydroShare resource.","title":"HS RDF HydroShare Python Client Resource Metadata Editing Examples"},{"location":"examples/Metadata_Operations/#install-the-hs-rdf-hydroshare-python-client","text":"The HS RDF Python Client for HydroShare won't be installed by default, so it has to be installed first before you can work with it. Use the following command to install the Python Client from the GitHub repository. Eventually we will distribute this package via the Python Package Index (PyPi) so that it can be installed via pip from PyPi. ! pip install hsclient","title":"Install the HS RDF HydroShare Python Client"},{"location":"examples/Metadata_Operations/#authenticate-with-hydroshare","text":"Before you start interacting with resources in HydroShare you will need to authenticate. from hsclient import HydroShare hs = HydroShare () hs . sign_in ()","title":"Authenticate with HydroShare"},{"location":"examples/Metadata_Operations/#create-a-new-empty-resource","text":"A \"resource\" is a container for your content in HydroShare. Think of it as a \"working directory\" into which you are going to organize the code and/or data you are using and want to share. The following code can be used to create a new, empty resource within which you can create content and metadata. This code creates a new resource in HydroShare. It also creates an in-memory object representation of that resource in your local environmment that you can then manipulate with further code. # Create the new, empty resource new_resource = hs . create () # Get the HydroShare identifier for the new resource resIdentifier = new_resource . resource_id print ( 'The HydroShare Identifier for your new resource is: ' + resIdentifier ) # Construct a hyperlink for the new resource print ( 'Your new resource is available at: ' + new_resource . metadata . url )","title":"Create a New Empty Resource"},{"location":"examples/Metadata_Operations/#creating-and-editing-resource-metadata-elements","text":"Editing metadata elements for a resource can be done in an object oriented way. You can specify all of the metadata elements in code, which will set their values in memory in your local environment. Values of metadata elements can be edited, removed, or replaced by setting them to a new value, appending new values (in the case where the metadata element accepts a list), or by removing the value entirely. When you are ready to save edits to metadata elements from your local environment to the resource in HydroShare, you can call the save() function on your resource and all of the new metadata values you created/edited will be saved to the resource in HydroShare.","title":"Creating and Editing Resource Metadata Elements"},{"location":"examples/Metadata_Operations/#resource-title-and-abstract","text":"The Title and Abstract metadata elements can be specified as text strings. To modify the Title or Abstract after it has been set, just set them to a different value. # Set the Title for the resource new_resource . metadata . title = 'Resource for Testing the HS RDF HydroShare Python Client' # Set the Abstract text for the resource new_resource . metadata . abstract = ( 'This resource was created as a demonstration of using the HS RDF ' 'Python Client for HydroShare. Once you have completed all of the ' 'steps in this notebook, you will have a fully populated HydroShare ' 'Resource.' ) # Call the save function to save the metadata edits to HydroShare new_resource . save () # Print the title just added to the resource print ( 'Title: ' + new_resource . metadata . title ) print ( 'Abstract: ' + new_resource . metadata . abstract )","title":"Resource Title and Abstract"},{"location":"examples/Metadata_Operations/#subject-keywords","text":"Subject keywords can be specified as a Python list of strings. Keywords can be added by creating a list, appending new keywords to the existing list, or by overriding the existing list with a new one. # Create subject keywords for the resource using a list of strings new_resource . metadata . subjects = [ 'HS RDF' , 'Python' , 'HydroShare' , 'Another Keyword' ] # New keywords can be appended to the existing list new_resource . metadata . subjects . append ( 'Hydroinformatics' ) # Keywords can be removed by removing them from the list new_resource . metadata . subjects . remove ( 'Another Keyword' ) # Save the changes to the resource in HydroShare new_resource . save () # Print the keywords for the resource print ( 'The list of keywords for the resource includes:' ) for keyword in new_resource . metadata . subjects : print ( keyword )","title":"Subject Keywords"},{"location":"examples/Metadata_Operations/#spatial-and-temporal-coverage","text":"Initially the spatial and temporal coverage for a resource are empty. To set them, you have to create a coverage object of the right type and set the spatial or temporal coverage to that object. # Import the required metadata classes for coverage objects from hsmodels.schemas.fields import BoxCoverage , PointCoverage , PeriodCoverage from datetime import datetime # Set the spatial coverage to a BoxCoverage object new_resource . metadata . spatial_coverage = BoxCoverage ( name = 'Logan, Utah' , northlimit = 41.7910 , eastlimit =- 111.7664 , southlimit = 41.6732 , westlimit =- 111.9079 , projection = 'WGS 84 EPSG:4326' , type = 'box' , units = 'Decimal degrees' ) # You can remove the spatial coverage element by setting it to None new_resource . metadata . spatial_coverage = None # If you want to set the spatial coverage to a PointCoverage instead new_resource . metadata . spatial_coverage = PointCoverage ( name = 'Logan, Utah' , north = 41.7371 , east =- 111.8351 , projection = 'WGS 84 EPSG:4326' , type = 'point' , units = 'Decimal degrees' ) # Create a beginning and ending date for a time period beginDate = datetime . strptime ( '2020-12-01T00:00:00Z' , '%Y-%m- %d T%H:%M:%S %f Z' ) endDate = datetime . strptime ( '2020-12-31T00:00:00Z' , '%Y-%m- %d T%H:%M:%S %f Z' ) # Set the temporal coverage of the resource to a PeriodCoverage object new_resource . metadata . period_coverage = PeriodCoverage ( start = beginDate , end = endDate ) # Save the changes to the resource in HydroShare new_resource . save () # Print the temporal coverage information print ( 'Temporal Coverage' ) print ( new_resource . metadata . period_coverage ) # Print the spatial coverage information print ( ' \\n Spatial Coverage' ) print ( new_resource . metadata . spatial_coverage )","title":"Spatial and Temporal Coverage"},{"location":"examples/Metadata_Operations/#additionalextended-metadata","text":"HydroShare allows you to create new, extended metadata elements for a HydroShare resource as key-value pairs. You can add new elements, edit existing elements, or remove these elements. Extended metadata elements are stored in the resource as a Python dictionary. # Add an extended metadata element as a key-value pair new_resource . metadata . additional_metadata [ 'New Element Key' ] = 'Text value of new element key.' # Remove an individual key-value pair using its key del new_resource . metadata . additional_metadata [ 'New Element Key' ] # Or, you can clear out all of the additional metadata elements that might exist new_resource . metadata . additional_metadata . clear () # Add multiple key-value pairs at once using a Python dictionary new_resource . metadata . additional_metadata = { 'Observed Variable' : 'Oxygen, dissolved' , 'Site Location' : 'Located on downstream side of river bridge' , 'Observation Depth' : '1 meter' } # Save the changes to the resource in HydroShare new_resource . save () # Print the extended metadata elements for the resource print ( 'The extended metadata elements for the resource include:' ) for key , value in new_resource . metadata . additional_metadata . items (): print ( key + ':' , value )","title":"Additional/Extended Metadata"},{"location":"examples/Metadata_Operations/#sources","text":"Sources are stored as a list of strings. Sources can be added or removed by adding or removing source strings from the list. # If you have existing Sources in your resource, you can remove all of them # by clearing the local list and then saving the resource new_resource . metadata . sources . clear () new_resource . save () # Add a Source to the resource sourceString = ( 'Mihalevich, B. A., Horsburgh, J. S., Melcher, A. A. (2017). High-frequency ' 'measurements reveal spatial and temporal patterns of dissolved organic ' 'matter in an urban water conveyance, Environmental Monitoring and ' 'Assessment, http://dx.doi.org/10.1007/s10661-017-6310-y.' ) new_resource . metadata . sources . append ( sourceString ) # Save the changes to the resource in HydroShare new_resource . save () # Print the Source metadata print ( 'The list of Sources includes:' ) for source in new_resource . metadata . sources : print ( source )","title":"Sources"},{"location":"examples/Metadata_Operations/#related-resources","text":"Related Resources are specified using a string that encodes the citation for the Related Resource along with a relationship type. Because of this, Related Resources are stored as a list of Relation objects. To create a new Related Resource, you have to first instantiate a Relation object and then add it to the list of Related Resources. # Import the required metadata class for a Relation object from hsmodels.schemas.fields import Relation from hsmodels.schemas.enums import RelationType # If you have existing Related Resources, you can remove all of them # by clearing the local list and then saving the resource new_resource . metadata . relations . clear () new_resource . save () # Create a new relation object newRelation = Relation ( type = RelationType . isDataFor , value = ( 'Bastidas Pacheco, C. J., Horsburgh, J. S., Tracy, ' 'R. J. (2020). A low-cost, open source monitoring ' 'system for collecting high-resolution water use ' 'data on magnetically-driven residential water ' 'meters, Sensors, 20(13), 3655, ' 'https://doi.org/10.3390/s20133655.' )) # Append the new Related Resource to the list of Related Resources new_resource . metadata . relations . append ( newRelation ) # Save the changes to the resource in HydroShare new_resource . save () # Print the list of Related Resources print ( 'The list of Related Resources includes:' ) for relatedResource in new_resource . metadata . relations : print ( relatedResource . type . value + ': ' + relatedResource . value )","title":"Related Resources"},{"location":"examples/Metadata_Operations/#funding-agency-credits","text":"Funding agency information contains multiple attributes when you add a funding agency to a HydroShare resource. You can create multiple funding agency entries for a resource, which get stored as a Python list. # Import the required metadata class for an AwardInfo object from hsmodels.schemas.fields import AwardInfo # If you have existing funding agency information, you can remove all of them # by clearing the local list and then saving the resource new_resource . metadata . awards . clear () new_resource . save () # Create a new AwardInfo object newAwardInfo = AwardInfo ( funding_agency_name = 'National Science Foundation' , title = ( 'Collaborative Research: Elements: Advancing Data Science ' 'and Analytics for Water (DSAW)' ), number = 'OAC 1931297' , funding_agency_url = 'https://www.nsf.gov/awardsearch/showAward?AWD_ID=1931297' ) # Append the new AwardInfo object to the list of funding agencies new_resource . metadata . awards . append ( newAwardInfo ) # Save the changes to the resource in HydroShare new_resource . save () # Print the AwardInfo print ( 'Funding sources added: ' ) for award in new_resource . metadata . awards : print ( 'Award Title: ' + award . title )","title":"Funding Agency Credits"},{"location":"examples/Metadata_Operations/#authors","text":"In HydroShare, an \"Author\" is the same as the Dublin Core metadata \"Creator\" element. The Creator element is a list of creators for the resource. However, the order of the Creators matters. When setting Creator information for the resource, you need to edit the local list of creators so that it reflects the order you want. When you call the save() function on the resource, the Creator information in HydroShare will be updated to match what you set locally. To add a new Creator to the list of Creators, you must first instantiate a Creator object and then add it to the list of Creators for the resource. Creator objects can be created by supplying all of the Creator metadata or by copying from a HydroShare user's profile. # Import the required metadata class for a Creator object from hsmodels.schemas.fields import Creator # Instantiate a new Creator object for a Creator that is a HydroShare user newCreator1 = Creator ( name = 'Jones, Amber Spackman' , organization = 'Utah State University' , email = 'amber.jones@usu.edu' , description = '/user/510/' ) # Append the new Creator to the resource's list of Creators new_resource . metadata . creators . append ( newCreator1 ) # Instantiate a new Creator object for a Creator that is not a HydroShare user newCreator2 = Creator ( name = 'Doe, John A.' , organization = 'Utah Water Research Laboratory' , email = 'john.doe@usu.edu' , address = '8200 Old Main Hill, Logan, UT 84322-8200' , phone = '123-456-7890' ) # Append the new Creator to the resource's list of Creators new_resource . metadata . creators . append ( newCreator2 ) # Instantiate a new Creator object for a Creator that is an organization newCreator3 = Creator ( organization = 'Utah Water Research Laboratory' , email = 'uwrl.receptionist@usu.edu' , address = '8200 Old Main Hill, Logan, UT 84322-8200' , homepage = 'http://uwrl.usu.edu' , phone = '435-797-3168 ' ) # Append the new Creator to the resource's list of Creators new_resource . metadata . creators . append ( newCreator3 ) # Instantiate a new Creator object using a HydroShare user object # First, retrieve HydroShare user object tony = hs . user ( 11 ) # Generate a Creator object from a HydroShare user object and append # the new Creator to the resource's list of Creators newCreator4 = Creator . from_user ( tony ) new_resource . metadata . creators . append ( newCreator4 ) # Save the changes to the resource in HydroShare new_resource . save () # Print the Creator names print ( 'The list of Creators includes: ' ) for creator in new_resource . metadata . creators : if creator . name is None : print ( creator . organization ) else : print ( creator . name ) The previous step leaves the resource with a list of 5 Creators. The order in which Creators appear in the metadata and on the Resource Landing Page is controlled by the order in which they appear in the the Creator list. To update the Creator order, update the order of the Creator list and then save the resource. # Change the order of the Creators in the list creatorOrder = [ 3 , 2 , 0 , 1 , 4 ] new_resource . metadata . creators = [ new_resource . metadata . creators [ i ] for i in creatorOrder ] # Save the changes to the resource in HydroShare new_resource . save () # Print the modified order of the Creator names print ( 'The list of Creators includes: ' ) for creator in new_resource . metadata . creators : if creator . name is None : print ( creator . organization ) else : print ( creator . name ) Creators can be removed by removing them from the local list of creators and then calling the save() function on the resource. Note that there must always be at least one creator. # Example of removing all but the first creator del new_resource . metadata . creators [ 1 :] new_resource . save () print ( 'Number of remaining creators: ' + str ( len ( new_resource . metadata . creators )))","title":"Authors"},{"location":"examples/Metadata_Operations/#contributors","text":"Contributors can be existing HydroShare users or others who do not have HydroShare accounts. Creating and removing contributors is similar to how Creators are handled. Contributors do not have a designated order. # Import the required metadata class for a Contributor object from hsmodels.schemas.fields import Contributor # Instantiate a new Contributor object for a Contributor that is not a HydroShare user newContributor1 = Contributor ( name = 'Horsburgh, Jeffery S.' , organization = 'Utah State University' , email = 'jeff.horsburgh@usu.edu' , phone = '(435) 797-2946' , ORCID = 'https://orcid.org/0000-0002-0768-3196' , address = 'Utah, US' , google_scholar_id = 'https://scholar.google.com/citations?user=mu4k534AAAAJ&hl=en' , homepage = 'http://jeffh.usu.edu' , research_gate_id = 'https://www.researchgate.net/profile/Jeffery_Horsburgh' ) # Append the new Contributor to the resource's list of Contributors new_resource . metadata . contributors . append ( newContributor1 ) # Instantiate a new Contributor object for a Contributor that is not a HydroShare user # Not all of the available metadata for a contributor have to be filled out newContributor2 = Contributor ( name = 'Doe, John A.' , organization = 'Utah State University' , email = 'john.doe@usu.edu' ) # Append the new Contributor to the resource's list of Contributors new_resource . metadata . contributors . append ( newContributor2 ) # Instantiate a new Contributor object using a HydroShare user object # First, retrieve HydroShare user object tony = hs . user ( 11 ) # Generate a Contributor object from the HydroShare user object newContributor3 = Contributor . from_user ( tony ) new_resource . metadata . contributors . append ( newContributor3 ) # Save the changes to the resource in HydroShare new_resource . save () # Print the Contributor names print ( 'The list of Contributors includes: ' ) for Contributor in new_resource . metadata . contributors : print ( Contributor . name ) Similar to other elements, if you want to remove Contributors, you can modify the local list of Creators and then call the save() function on the resource to save the changes in HydroShare. # Clear the list of Contributors and save to HydroShare new_resource . metadata . contributors . clear () new_resource . save () print ( 'Number of remaining Contributors: ' + str ( len ( new_resource . metadata . contributors )))","title":"Contributors"},{"location":"examples/Metadata_Operations/#license-and-rights-statement","text":"The license under which a Resource is shared can be modified. HydroShare defaults to one of the Creative Commons licenses, but you can change it to a license that meets your needs. The license consists of a rights statement stored as as string and a URL that is a link to a description of the license on the Internet. # Import the required metadata class for a Rights object from hsmodels.schemas.fields import Rights # Set the rights statement and the URL that points to its description new_resource . metadata . rights . statement = ( 'This resource is shared under the Creative Commons ' 'Attribution-NoCommercial-NoDerivs CC BY-NC-ND.' ) new_resource . metadata . rights . url = 'http://creativecommons.org/licenses/by-nc-nd/4.0/' # Save the changes to the resource in HydroShare new_resource . save () # Print the rights statement: print ( new_resource . metadata . rights . statement ) print ( new_resource . metadata . rights . url ) # You can also use one of the available, pre-generated Rights Statements # available in HydroShare new_resource . metadata . rights = Rights . Creative_Commons_Attribution_CC_BY () new_resource . save () # Print the rights statement: print ( new_resource . metadata . rights . statement ) print ( new_resource . metadata . rights . url )","title":"License and Rights Statement"},{"location":"metadata/FileSet/","text":"rights: Rights pydantic-field An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared type: AggregationType pydantic-field A string expressing the aggregation type from the list of HydroShare aggregation types url: AnyUrl pydantic-field required An object containing the URL of the aggregation additional_metadata: str pydantic-field A list of extended metadata elements expressed as key-value pairs language: str pydantic-field The 3-character string for the language in which the metadata and content are expressed period_coverage: PeriodCoverage pydantic-field An object containing the temporal coverage for a aggregation expressed as a date range spatial_coverage: Union[hsmodels.schemas.fields.PointCoverage, hsmodels.schemas.fields.BoxCoverage] pydantic-field An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point subjects: str pydantic-field A list of keyword strings expressing the topic of the aggregation title: str pydantic-field A string containing a descriptive title for the aggregation","title":"File Set"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.FileSetMetadata","text":"","title":"hsmodels.schemas.aggregations.FileSetMetadata"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.FileSetMetadata.rights","text":"An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared","title":"rights"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.FileSetMetadata.type","text":"A string expressing the aggregation type from the list of HydroShare aggregation types","title":"type"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.FileSetMetadata.url","text":"An object containing the URL of the aggregation","title":"url"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn","text":"","title":"hsmodels.schemas.aggregations.BaseAggregationMetadataIn"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.additional_metadata","text":"A list of extended metadata elements expressed as key-value pairs","title":"additional_metadata"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.language","text":"The 3-character string for the language in which the metadata and content are expressed","title":"language"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.period_coverage","text":"An object containing the temporal coverage for a aggregation expressed as a date range","title":"period_coverage"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.spatial_coverage","text":"An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point","title":"spatial_coverage"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.subjects","text":"A list of keyword strings expressing the topic of the aggregation","title":"subjects"},{"location":"metadata/FileSet/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.title","text":"A string containing a descriptive title for the aggregation","title":"title"},{"location":"metadata/GeographicFeature/","text":"rights: Rights pydantic-field An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared type: AggregationType pydantic-field A string expressing the aggregation type from the list of HydroShare aggregation types url: AnyUrl pydantic-field required An object containing the URL of the aggregation additional_metadata: str pydantic-field A list of extended metadata elements expressed as key-value pairs language: str pydantic-field The 3-character string for the language in which the metadata and content are expressed period_coverage: PeriodCoverage pydantic-field An object containing the temporal coverage for a aggregation expressed as a date range spatial_coverage: Union[hsmodels.schemas.fields.PointCoverage, hsmodels.schemas.fields.BoxCoverage] pydantic-field An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point subjects: str pydantic-field A list of keyword strings expressing the topic of the aggregation title: str pydantic-field A string containing a descriptive title for the aggregation","title":"Geographic Feature"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.GeographicFeatureMetadata","text":"","title":"hsmodels.schemas.aggregations.GeographicFeatureMetadata"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.GeographicFeatureMetadata.rights","text":"An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared","title":"rights"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.GeographicFeatureMetadata.type","text":"A string expressing the aggregation type from the list of HydroShare aggregation types","title":"type"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.GeographicFeatureMetadata.url","text":"An object containing the URL of the aggregation","title":"url"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn","text":"","title":"hsmodels.schemas.aggregations.BaseAggregationMetadataIn"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.additional_metadata","text":"A list of extended metadata elements expressed as key-value pairs","title":"additional_metadata"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.language","text":"The 3-character string for the language in which the metadata and content are expressed","title":"language"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.period_coverage","text":"An object containing the temporal coverage for a aggregation expressed as a date range","title":"period_coverage"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.spatial_coverage","text":"An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point","title":"spatial_coverage"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.subjects","text":"A list of keyword strings expressing the topic of the aggregation","title":"subjects"},{"location":"metadata/GeographicFeature/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.title","text":"A string containing a descriptive title for the aggregation","title":"title"},{"location":"metadata/GeographicRaster/","text":"rights: Rights pydantic-field An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared type: AggregationType pydantic-field A string expressing the aggregation type from the list of HydroShare aggregation types url: AnyUrl pydantic-field required An object containing the URL of the aggregation additional_metadata: str pydantic-field A list of extended metadata elements expressed as key-value pairs language: str pydantic-field The 3-character string for the language in which the metadata and content are expressed period_coverage: PeriodCoverage pydantic-field An object containing the temporal coverage for a aggregation expressed as a date range spatial_coverage: Union[hsmodels.schemas.fields.PointCoverage, hsmodels.schemas.fields.BoxCoverage] pydantic-field An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point subjects: str pydantic-field A list of keyword strings expressing the topic of the aggregation title: str pydantic-field A string containing a descriptive title for the aggregation","title":"Geographic Raster"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.GeographicRasterMetadata","text":"","title":"hsmodels.schemas.aggregations.GeographicRasterMetadata"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.GeographicRasterMetadata.rights","text":"An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared","title":"rights"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.GeographicRasterMetadata.type","text":"A string expressing the aggregation type from the list of HydroShare aggregation types","title":"type"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.GeographicRasterMetadata.url","text":"An object containing the URL of the aggregation","title":"url"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn","text":"","title":"hsmodels.schemas.aggregations.BaseAggregationMetadataIn"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.additional_metadata","text":"A list of extended metadata elements expressed as key-value pairs","title":"additional_metadata"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.language","text":"The 3-character string for the language in which the metadata and content are expressed","title":"language"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.period_coverage","text":"An object containing the temporal coverage for a aggregation expressed as a date range","title":"period_coverage"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.spatial_coverage","text":"An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point","title":"spatial_coverage"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.subjects","text":"A list of keyword strings expressing the topic of the aggregation","title":"subjects"},{"location":"metadata/GeographicRaster/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.title","text":"A string containing a descriptive title for the aggregation","title":"title"},{"location":"metadata/ModelInstance/","text":"rights: Rights pydantic-field An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared type: AggregationType pydantic-field A string expressing the aggregation type from the list of HydroShare aggregation types url: AnyUrl pydantic-field required An object containing the URL of the aggregation additional_metadata: str pydantic-field A list of extended metadata elements expressed as key-value pairs language: str pydantic-field The 3-character string for the language in which the metadata and content are expressed period_coverage: PeriodCoverage pydantic-field An object containing the temporal coverage for a aggregation expressed as a date range spatial_coverage: Union[hsmodels.schemas.fields.PointCoverage, hsmodels.schemas.fields.BoxCoverage] pydantic-field An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point subjects: str pydantic-field A list of keyword strings expressing the topic of the aggregation title: str pydantic-field A string containing a descriptive title for the aggregation","title":"Model Instance"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.ModelInstanceMetadata","text":"","title":"hsmodels.schemas.aggregations.ModelInstanceMetadata"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.ModelInstanceMetadata.rights","text":"An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared","title":"rights"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.ModelInstanceMetadata.type","text":"A string expressing the aggregation type from the list of HydroShare aggregation types","title":"type"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.ModelInstanceMetadata.url","text":"An object containing the URL of the aggregation","title":"url"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn","text":"","title":"hsmodels.schemas.aggregations.BaseAggregationMetadataIn"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.additional_metadata","text":"A list of extended metadata elements expressed as key-value pairs","title":"additional_metadata"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.language","text":"The 3-character string for the language in which the metadata and content are expressed","title":"language"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.period_coverage","text":"An object containing the temporal coverage for a aggregation expressed as a date range","title":"period_coverage"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.spatial_coverage","text":"An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point","title":"spatial_coverage"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.subjects","text":"A list of keyword strings expressing the topic of the aggregation","title":"subjects"},{"location":"metadata/ModelInstance/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.title","text":"A string containing a descriptive title for the aggregation","title":"title"},{"location":"metadata/ModelProgram/","text":"rights: Rights pydantic-field An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared type: AggregationType pydantic-field A string expressing the aggregation type from the list of HydroShare aggregation types url: AnyUrl pydantic-field required An object containing the URL of the aggregation additional_metadata: str pydantic-field A list of extended metadata elements expressed as key-value pairs language: str pydantic-field The 3-character string for the language in which the metadata and content are expressed period_coverage: PeriodCoverage pydantic-field An object containing the temporal coverage for a aggregation expressed as a date range spatial_coverage: Union[hsmodels.schemas.fields.PointCoverage, hsmodels.schemas.fields.BoxCoverage] pydantic-field An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point subjects: str pydantic-field A list of keyword strings expressing the topic of the aggregation title: str pydantic-field A string containing a descriptive title for the aggregation","title":"Model Program"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.ModelProgramMetadata","text":"","title":"hsmodels.schemas.aggregations.ModelProgramMetadata"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.ModelProgramMetadata.rights","text":"An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared","title":"rights"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.ModelProgramMetadata.type","text":"A string expressing the aggregation type from the list of HydroShare aggregation types","title":"type"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.ModelProgramMetadata.url","text":"An object containing the URL of the aggregation","title":"url"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn","text":"","title":"hsmodels.schemas.aggregations.BaseAggregationMetadataIn"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.additional_metadata","text":"A list of extended metadata elements expressed as key-value pairs","title":"additional_metadata"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.language","text":"The 3-character string for the language in which the metadata and content are expressed","title":"language"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.period_coverage","text":"An object containing the temporal coverage for a aggregation expressed as a date range","title":"period_coverage"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.spatial_coverage","text":"An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point","title":"spatial_coverage"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.subjects","text":"A list of keyword strings expressing the topic of the aggregation","title":"subjects"},{"location":"metadata/ModelProgram/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.title","text":"A string containing a descriptive title for the aggregation","title":"title"},{"location":"metadata/Multidimensional/","text":"rights: Rights pydantic-field An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared type: AggregationType pydantic-field A string expressing the aggregation type from the list of HydroShare aggregation types url: AnyUrl pydantic-field required An object containing the URL of the aggregation additional_metadata: str pydantic-field A list of extended metadata elements expressed as key-value pairs language: str pydantic-field The 3-character string for the language in which the metadata and content are expressed period_coverage: PeriodCoverage pydantic-field An object containing the temporal coverage for a aggregation expressed as a date range spatial_coverage: Union[hsmodels.schemas.fields.PointCoverage, hsmodels.schemas.fields.BoxCoverage] pydantic-field An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point subjects: str pydantic-field A list of keyword strings expressing the topic of the aggregation title: str pydantic-field A string containing a descriptive title for the aggregation","title":"Multidimensional"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.MultidimensionalMetadata","text":"","title":"hsmodels.schemas.aggregations.MultidimensionalMetadata"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.MultidimensionalMetadata.rights","text":"An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared","title":"rights"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.MultidimensionalMetadata.type","text":"A string expressing the aggregation type from the list of HydroShare aggregation types","title":"type"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.MultidimensionalMetadata.url","text":"An object containing the URL of the aggregation","title":"url"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn","text":"","title":"hsmodels.schemas.aggregations.BaseAggregationMetadataIn"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.additional_metadata","text":"A list of extended metadata elements expressed as key-value pairs","title":"additional_metadata"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.language","text":"The 3-character string for the language in which the metadata and content are expressed","title":"language"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.period_coverage","text":"An object containing the temporal coverage for a aggregation expressed as a date range","title":"period_coverage"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.spatial_coverage","text":"An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point","title":"spatial_coverage"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.subjects","text":"A list of keyword strings expressing the topic of the aggregation","title":"subjects"},{"location":"metadata/Multidimensional/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.title","text":"A string containing a descriptive title for the aggregation","title":"title"},{"location":"metadata/ReferencedTimeSeries/","text":"rights: Rights pydantic-field An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared type: AggregationType pydantic-field A string expressing the aggregation type from the list of HydroShare aggregation types url: AnyUrl pydantic-field required An object containing the URL of the aggregation additional_metadata: str pydantic-field A list of extended metadata elements expressed as key-value pairs language: str pydantic-field The 3-character string for the language in which the metadata and content are expressed period_coverage: PeriodCoverage pydantic-field An object containing the temporal coverage for a aggregation expressed as a date range spatial_coverage: Union[hsmodels.schemas.fields.PointCoverage, hsmodels.schemas.fields.BoxCoverage] pydantic-field An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point subjects: str pydantic-field A list of keyword strings expressing the topic of the aggregation title: str pydantic-field A string containing a descriptive title for the aggregation","title":"Referenced Time Series"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.ReferencedTimeSeriesMetadata","text":"","title":"hsmodels.schemas.aggregations.ReferencedTimeSeriesMetadata"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.ReferencedTimeSeriesMetadata.rights","text":"An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared","title":"rights"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.ReferencedTimeSeriesMetadata.type","text":"A string expressing the aggregation type from the list of HydroShare aggregation types","title":"type"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.ReferencedTimeSeriesMetadata.url","text":"An object containing the URL of the aggregation","title":"url"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn","text":"","title":"hsmodels.schemas.aggregations.BaseAggregationMetadataIn"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.additional_metadata","text":"A list of extended metadata elements expressed as key-value pairs","title":"additional_metadata"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.language","text":"The 3-character string for the language in which the metadata and content are expressed","title":"language"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.period_coverage","text":"An object containing the temporal coverage for a aggregation expressed as a date range","title":"period_coverage"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.spatial_coverage","text":"An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point","title":"spatial_coverage"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.subjects","text":"A list of keyword strings expressing the topic of the aggregation","title":"subjects"},{"location":"metadata/ReferencedTimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.title","text":"A string containing a descriptive title for the aggregation","title":"title"},{"location":"metadata/SingleFile/","text":"rights: Rights pydantic-field An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared type: AggregationType pydantic-field A string expressing the aggregation type from the list of HydroShare aggregation types url: AnyUrl pydantic-field required An object containing the URL of the aggregation additional_metadata: str pydantic-field A list of extended metadata elements expressed as key-value pairs language: str pydantic-field The 3-character string for the language in which the metadata and content are expressed period_coverage: PeriodCoverage pydantic-field An object containing the temporal coverage for a aggregation expressed as a date range spatial_coverage: Union[hsmodels.schemas.fields.PointCoverage, hsmodels.schemas.fields.BoxCoverage] pydantic-field An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point subjects: str pydantic-field A list of keyword strings expressing the topic of the aggregation title: str pydantic-field A string containing a descriptive title for the aggregation","title":"Single File"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.SingleFileMetadata","text":"","title":"hsmodels.schemas.aggregations.SingleFileMetadata"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.SingleFileMetadata.rights","text":"An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared","title":"rights"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.SingleFileMetadata.type","text":"A string expressing the aggregation type from the list of HydroShare aggregation types","title":"type"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.SingleFileMetadata.url","text":"An object containing the URL of the aggregation","title":"url"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn","text":"","title":"hsmodels.schemas.aggregations.BaseAggregationMetadataIn"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.additional_metadata","text":"A list of extended metadata elements expressed as key-value pairs","title":"additional_metadata"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.language","text":"The 3-character string for the language in which the metadata and content are expressed","title":"language"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.period_coverage","text":"An object containing the temporal coverage for a aggregation expressed as a date range","title":"period_coverage"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.spatial_coverage","text":"An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point","title":"spatial_coverage"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.subjects","text":"A list of keyword strings expressing the topic of the aggregation","title":"subjects"},{"location":"metadata/SingleFile/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.title","text":"A string containing a descriptive title for the aggregation","title":"title"},{"location":"metadata/TimeSeries/","text":"rights: Rights pydantic-field An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared type: AggregationType pydantic-field A string expressing the aggregation type from the list of HydroShare aggregation types url: AnyUrl pydantic-field required An object containing the URL of the aggregation additional_metadata: str pydantic-field A list of extended metadata elements expressed as key-value pairs language: str pydantic-field The 3-character string for the language in which the metadata and content are expressed period_coverage: PeriodCoverage pydantic-field An object containing the temporal coverage for a aggregation expressed as a date range spatial_coverage: Union[hsmodels.schemas.fields.PointCoverage, hsmodels.schemas.fields.BoxCoverage] pydantic-field An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point subjects: str pydantic-field A list of keyword strings expressing the topic of the aggregation title: str pydantic-field A string containing a descriptive title for the aggregation","title":"Time Series"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.TimeSeriesMetadata","text":"","title":"hsmodels.schemas.aggregations.TimeSeriesMetadata"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.TimeSeriesMetadata.rights","text":"An object containing information about the rights held in and over the aggregation and the license under which a aggregation is shared","title":"rights"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.TimeSeriesMetadata.type","text":"A string expressing the aggregation type from the list of HydroShare aggregation types","title":"type"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.TimeSeriesMetadata.url","text":"An object containing the URL of the aggregation","title":"url"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn","text":"","title":"hsmodels.schemas.aggregations.BaseAggregationMetadataIn"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.additional_metadata","text":"A list of extended metadata elements expressed as key-value pairs","title":"additional_metadata"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.language","text":"The 3-character string for the language in which the metadata and content are expressed","title":"language"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.period_coverage","text":"An object containing the temporal coverage for a aggregation expressed as a date range","title":"period_coverage"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.spatial_coverage","text":"An object containing the geospatial coverage for the aggregation expressed as either a bounding box or point","title":"spatial_coverage"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.subjects","text":"A list of keyword strings expressing the topic of the aggregation","title":"subjects"},{"location":"metadata/TimeSeries/#hsmodels.schemas.aggregations.BaseAggregationMetadataIn.title","text":"A string containing a descriptive title for the aggregation","title":"title"}]}